---
title: "ProyectoAED2023"
author: "Carlos, Diego, Miguel"
date: "2023-11-02"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introducción

En el presente informe planteamos el análisis exploratorio de un conjunto de datos sobre la calidad del aire de la ciudad de Valencia entre 2004 y 2022. El dataset empleado continene observaciones obtenidas de distintas estaciones de la red de vigilancia de Valencia. Las observaciones están compuestas por variables respectivas a diversas moleculas y elementos presentes en el aire junto a otras de tipo meteorológico como la velocidad del viento, la temperatura, etc.

El procedimiento a seguir comenzará con la correcta importación del dataset, a lo que seguirá la preparación de los datos para resolver las preguntas planteadas. Se escogerán las variables de interés y los periodos temporales sobre los que se realizará el análisis, se aplicarán las transformaciones necesarias sobre las variables, se reestructurará el dataset acorde a nuestras necesidades y se gestionarán los outliers y datos faltantes.

Una vez preparado el dataset, procederemos a responder a las preguntas planteadas mediante diversas metodologías. Todo el proceso irá acompañado de las explicaciones pertinentes y finalizaremos con una conclusión del trabajo realizado.



# Objetivos

El objetivo principal de este trabajo es familizarse con las herramientas y metodologías aprendidas para la carga, manipulación y análisis exploratorio de un conjunto de datos. Para ello se van a plantear una serie de objetivos es forma de preguntas que requerirán la aplicación de las herramientas y metodologías aprendidas:

+ ¿?Influencia del cambio en el tráfico hacia el centro de la ciudad en los últimos años. (carriles bici) : Comprobar posible reducción de gases emitidos por vehículos a motor en las estaciones más céntricas.

+ ¿?Relación radiación solar con ozono

+ ¿?Existe cierta evolución de la contaminación sonora (años/zonas)

+ ¿?Existe cierta evolución de la temperatura

+ ¿?Existe cierta evolución de la contaminación. Como medir la contaminación

+ ¿?Existe alguna diferencia entre las distintas estaciones

+ ¿?Existe alguna correlación entre la calidad del aire y el día de la semana/año

+ ...

A lo largo del desarrollo del proyecto se irán planteando y resolviendo las preguntas anteriores junto a su razonamiento y conclusiones.



# Carga de librerías y datos

[Explicar la estructura del dataset sin modificar]

[Escoger variables para "calidad del aire"]



```{r}
library(readr) # Carga de datos
library(lubridate) # Manejo de datos
library(tidyr) # Manejo de datos
library(dplyr) # Manejo de datos
library(ggplot2) # Visualización de datos
```


```{r}
column_types <- cols(
  Fecha = col_date(format = "%Y-%m-%d"),
  `Dia de la semana` = col_factor(levels = c("Lunes", "Martes",  "Miercoles", "Jueves", "Viernes", "Sabado", "Domingo")), `Dia del mes` = col_factor(levels = as.character(1:31)),
  Estacion = col_factor())

datos <- read_delim("data/rvvcca.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE, col_types = column_types)


#columnas_eliminadas <- c("Fecha creacion","Fecha baja")
#datos <- datos[,!names(datos) %in% columnas_eliminadas]

# renombramos las varianles con espacios en su nombre para trabajar sin comillas ' ' y cambiamos el superíndice de ³ (ng/m³) por un 3 normal
#colnames(datos) <- gsub(x = colnames(datos), pattern=' ', replacement = '_')
#colnames(datos) <- gsub(x = colnames(datos), pattern='³', replacement = '3')
```

# Separar dataframe principal en una lista de dataframes por estaciones
```{r}
estaciones <- unique(datos$Estacion)
datos_separados <- list()

for(s in estaciones){
  datos_estacion <- datos[datos$Estacion == s,]
  datos_separados <- append(datos_separados,list(datos_estacion))
}

names(datos_separados) <- estaciones
```

# Exploración inicial de los datos

summary de las variables, ver proporcion de datos faltantes, ver periodos temporales de recogida de las variables, etc. con el objetivo de escoger las variables necesarias para nuestros objetivos

Para tener una primera visión de nuestros datos usamos las funciones *glimpse* y *summary*, que nos proporcionan información básica sobre nuestro data.frame. Por una parte *glimpse*, proporciona el número de variables y observaciones, así como la clase de las distintas variables y una pequeña muestra de valores de cada variable. Por otro lado *summary* nos proporciona información estadística de cada variable en función de su clase (numérico, factor...), así como su número de datos faltantes (NA's).

```{r}
glimpse(datos)
summary(datos)
```

Combinando estas funciones vemos que:

- *Id* es un identificador que puede haber sido usado a la hora de combinar datos en este dataset. Su información estadistica por tanto no tiene ningín valor.

- *Fecha* es una variable tipo *date* que nos proporciona la fecha en que se tomaron las medidas de las distintas variables. Tomaremos esta variable para la ordenación ascendente de los datos.

- *Dia_de_la_semana* y *Dia_del_mes* son variables de tipo factor que indican en que día de la semana y en qué dia del mes se realiza la medida. Puede ser extraído a partir de *Fecha*. Como podemos acceder a estos valores mediante la librería _lubridate_ y la variable *Fecha* podemos prescindir de ellas.

- *Estacion* es una variable de tipo factor cuyos niveles son las distintas estaciones meteorológicas donde se tomaron las mediciones de las variables numéricas.

- *PM1, PM2.5, PM10* son variables de tipo numérico con datos sobre la concentración de materiales particuldos (OM) de menos de 1, 2.5 y 10 micrómetros de diámetro respectivamente. Las tres variables presentan un número elevado de NA's.

- *NO, NO2, NOx, O2, SO2, CO, NH3* son variables con datos sobre la concentración de estas moléculas inorgánicas consideradas contaminantes en el aire. *NO, NO2* y *NOx* presentan un número similar de NA's lo que puede ser indicativo de que estos datos han sido tomados a la vez. El resto de variables presenta un número mayor de NA's.

- *C7H8, C6H6, C8H10* son variables con datos sobre la concentración de estas moléculas orgánicas consideradas contaminantes en el aire. También presentan un número similar de NA's por lo que estos datos pueden a¡haber sido tomados a la vez.

- *Velocidad_del_viento, Direccion_del_viento, Temperatura, Humidad_relativa, Presion, Radiacion_solar, Precipitacion, Velocidad_maxima_del_viento* son variables numéricas con mediciones de estas distintas condiciones meteorológicas al momento de medir las concentraciones de moléculas contaminantes en el aire. Es interesante contar con estos datos para ver si influyen en los valores de contaminación. la velocidad y la dirección del viento tienen un número similar de NA's al igual que la temperatura, la humedad relativa, la presión y la radiación solar y las precipitaciones y la velocidad máxima del viento. En todos ls casos tenemos un número elevado de NA's.

- *As_(ng/m3), Ni_(ng/m3), Cd_(ng/m3), Pb_(ng/m3), B(a)p_(ng/m3)* son variables numéricas con datos de otras concentraciones de gases y metales contaminantes en el aire. Todos tienen el mismo número NA's por lo que de nuevo parecen haber sido medidos al mismo tiempo.

La conclusión de este primer análisis de los datos es que este dataset parece haber sido construido a partir de la unión de otros datasets, lo cuál explica que hayan tantos datos faltantes, ya que los datos de distintos datasets se tomaron en periódos de tiempo distintos, y al unirlos por la fecha queda una gran cantidad de NA's. Esto implica trabajar en distintos intervalos temporales para cada una de las preguntas que pretendamos responder.

Vamos a comenzar eliminando algunas variables. Como hemos mencionado previamente, no necesitamos las variables *Dia_de_la_semana* y *Dia_del_mes* debido a que podemos acceder a estos valores mediante _wday()_ y _day()_, de la librería _lubridate_, respectivamente. Es importante recalcar que para _lurbidate_ el día 1 de la semana es el Domingo.

```{r}
datos <- datos[,!(colnames(datos) %in% c("Dia del mes", "Dia de la semana"))]
```

Por otro lado, podemos intuir mediante el summary previo que la variable *Fecha creación* es peculiar. La analizamos individualmente.

```{r}
# Vemos los valores que toma y sus apariciones
table(datos$`Fecha creacion`)
```

Vemos que solo toma dos valores que no nos aportan ninguna información relevante, por lo que la vamos a eliminar junto a la variable *Fecha baja* ya que esta solo toma valores NA.

```{r}
datos <- datos[,!(colnames(datos) %in% c("Fecha creacion", "Fecha baja"))]
```

También vamos a ordenar el dataset por Fecha en orden ascendente
```{r}
datos <- arrange(datos,datos$Fecha)
```

Como hemos visto que nuestro dataset contiene un número muy significante de NA's, vamos a calcular el porcentaje de NA's de cada una de las variabes de nuestro dataset:
```{r}
# Porcentaje de datos faltantes en cada variable
sapply(lapply(datos, is.na), sum)*100/nrow(datos)
```

A continuación queremos visualizar el período de tiempo entre la primera y la última medida de cada variable

```{r}
# Alternativa: creamos una lista de dataframes, uno para cada variable, conteniendo las observaciones que no son NA
# La primera observación es el inicio de la toma de muestras y la última el fin, ya que se ha ordenado por fecha previamente
series_temporales <- list()
variables <- colnames(datos)[4:length(colnames(datos))]

for (i in 1:length(variables) ) {
  df <- data.frame(fecha = datos$Fecha, valor = datos[[variables[i]]]) %>% na.omit
  series_temporales[[i]] <- df
}
names(series_temporales) <- variables

ggplot() + geom_line(data = series_temporales[[1]], aes(fecha,valor)) + ylab(variables[1])
```

```{r}
# Construimos el cata.frame 'segmentos' que contiene la primera y la última fecha con datos de cada una de nuestras variables numéricas
segmentos <- data.frame(variable = colnames(datos)[6:length(colnames(datos))])
fecha_inicio <- as.Date(rep(0,nrow(segmentos)))
fecha_fin <- as.Date(rep(0,nrow(segmentos)))
porc_na <- rep(0,nrow(segmentos))
for (i in 1:nrow(segmentos)) {
  # fecha de la primera entrada con datos de la variable i
  fecha_inicio[i] <- datos$Fecha[!is.na(datos[,segmentos[i,1]])][1]
  # fecha de la última entrada con datos de la variable i
  fecha_fin[i] <- datos$Fecha[!is.na(datos[,segmentos[i,1]])][length(datos$Fecha[!is.na(datos[,segmentos[i,1]])])]
  filtro <- filter(datos, Fecha >= fecha_inicio[i], Fecha <= fecha_fin[i])
  # porcentaje de datos faltantes en la variable i desde la primera entrada con datos hasta la última
  porc_na[i] <- sum(is.na(filtro[,segmentos[i,1]]))*100/nrow(filtro)
}
segmentos$fecha_inicio <- fecha_inicio
segmentos$fecha_fin <- fecha_fin
segmentos$porc_na <- porc_na

# Representamos los segmentos de tiempo entre los que hay datos para cada una de las variables
ggplot(data = segmentos, aes(y = variable, color = porc_na)) + geom_segment(aes(x = fecha_inicio, xend = fecha_fin, yend = variable), lwd = 1.2) + geom_point(aes(x = fecha_inicio)) + geom_point(aes(x = fecha_fin)) + labs(title = 'Período de tiempo entre la primera y la última medida', x = 'Fecha') + scale_color_gradient("Porcentaje NA's", low = 'blue',high = 'red')
```

A partir de este gráfico podemos ver como algunas variables empiezan a ser medidas a partir de cierta fecha. En concreto, los datos de *As*, *Cd*, *NH3*, *Ni*, *Pb* y *Prceipitacióo* empiezan a tomarse sólo a partir de 2019. En el caso del *B(a)* solo tenemos una entrada por lo que debemos dejar de considerar esta variable. Otras variables como *Velocidad_maxima_del_viento*  o *PM1* empiezan a tener datos un poco más tarde que el resto pero antes del 2019. Todas las demás variables presentan almenos algún dato en 2004. Por otro lado, los datos de *As*, *Ni*, *Cd* y *Ob* terminan antes que el resto de variables, a principios del 2022. Además, en el dódigo de colores se muestra el porcentaje de datos faltantes de cada variable en el período que ba desde la fecha de la primera toma de datos de esta variable hasta la fecha de la última. Cabe destacar en este aspecto que las variables *As*, *Cd*, *NH3*, *Ni*, *Pb*, tienen un porcentaje muy elevado de NA's (alrededor del 90%) al igual que las variabñes *C8H10*, *C7H8* y *C6H6*, pero en un período de tiempo mucho más pequeño.

También queremos ver qué estaciones meteorológicas han estado recogiendo datos a lo largo de los años
```{r}
estaciones_anos <- datos %>% mutate(ano = factor(year(Fecha))) %>% select(c('ano','Estacion'))
ggplot(data = estaciones_anos, aes(x=ano, fill = Estacion)) + geom_bar() + labs(x = 'Año') + theme(axis.text.x=element_text(angle=45, hjust=1))
```

Como podemos ver, desde 2004 hasta 2007 sólo tenemos datos de las estaciones de Pista de Silla y Viveros y posteriormente en los siguientes 5 años se van añadiendo datos de otras estaciones como la del Politécnico, Av. de Francia, Molí del Sol, Boulevard Sur, Valencia Centro y Conselleria a razón casi de una nueva estación al año. Desde 2013 hasta 2016 se mantienen las mismas estaciones y en los siguientes dos años se añaden datos de la estación del Puerto de Valencia, de la que posteriormente dejamos de obtener datos. Finalmente desde 2019 hasta 2022 se van añadiendo progresivamente cada año las estaciones de Nazaret, Puerto Molí Trans. Ponent, Puerto antic Turia y Valencia Olivereta. 2022 es el año donde tenemos datos de más estaciones distintas.

## Limpieza de datos

En esta sección nos encargaremos de imputar los NA para no eliminar instancias en los datos y deshacernos de los outliers.

```{r}
tresSigma <- function(x){
  media <- mean(x,na.rm=TRUE)
  desviacion <- sd(x,na.rm=TRUE)
  lim_low <- media - 3 * desviacion
  lim_upp <- media + 3 * desviacion
  
  outliers <- x[x < lim_low | x > lim_upp]
  
  return(outliers)
}

hampel <- function(x){
  mediana <- median(x, na.rm = TRUE)
  madm <- mad(x, constant = 1.4826, na.rm = TRUE)
  umbral <- 3 * madm
  
  outliers <- x[abs(x-mediana) > umbral]
  
  return(outliers)
}

boxplot <- function(x){
  q1 <- quantile(x, 0.25, na.rm = TRUE)
  q3 <- quantile(x, 0.75, na.rm = TRUE)
  
  iqr <- q3 - q1
  
  lower_limit <- q1 - 1.5 * iqr
  upper_limit <- q3 + 1.5 * iqr
  
  outliers <- x[x < lower_limit | x > upper_limit]
  
  return(outliers)
}

percentil <- function(x){
  p5 <- quantile(x, 0.05, na.rm = TRUE)
  p95 <- quantile(x, 0.95, na.rm = TRUE)
  
  outliers <- x[x < p5 | x > p95]
  
  return(outliers)
}

remove_outliers <- function(x, func) {
  outliers <- func(x)
  return(x[!is.na(outliers)])
}

replace_outliers <- function(x, func) {
  outliers <- func(x)
  x[outliers] <- NA
  return(x)
}
```

Vamos a comprobar el funcionamiento de los métodos de detección de outliers. Lo aplicaremos sobre todas las variables numéricas referentes a 
```{r}
columnas_numericas <- setdiff(names(datos)[sapply(datos, is.numeric)], c("Id", "Dirección del viento"))

m1 <- apply(datos[columnas_numericas], 2, tresSigma)
m2 <- apply(datos[columnas_numericas], 2, hampel)
m3 <- apply(datos[columnas_numericas], 2, boxplot)
m4 <- apply(datos[columnas_numericas], 2, percentil)

m1 <- sapply(sapply(m1, complete.cases),sum)
m2 <- sapply(sapply(m2, complete.cases),sum)
m3 <- sapply(sapply(m3, complete.cases),sum)
m4 <- sapply(sapply(m4, complete.cases),sum)

resultados <- data.frame(
  Metodo = rep(c("3-Sigma", "Hampel", "Boxplot", "Percentil"), each = length(columnas_numericas)),
  Columna = rep(columnas_numericas, times = 4),
  Outliers_Detectados = c(m1, m2, m3, m4)
)

ggplot(resultados, aes(x = Columna, y = Outliers_Detectados, fill = Metodo)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(title = "Número de Outliers Detectados por Método",
       x = "Columna Numérica",
       y = "Número de Outliers Detectados") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


Usaremos el metodo de Hampel, ya que por la naturaleza de los datos no podemos suponer los datos como una distribución Gaussiana.

A continuación, reemplazaremos los outliers por NA.

```{r}
datos_clean_outliers <- datos %>%
  mutate_at(vars(all_of(columnas_numericas)), ~ replace_outliers(., hampel))
```


# Influencia de carril bici

Para estudiar la influencia de un carril bici por el centro de Valencia, estudiaremos la evolución de gases contaminantes en diversas estaciones de la ciudad. Mediremos la evolución de los gases:

+ SO2: Originado sobre todo durante la combustión de carburantes fósiles.
+ NO2: Es un contaminante atmosférico cuyas fuentes fundamentales son el tráfico rodado, así como las emisiones de determinadas industrias y grandes instalaciones de combustión.

Además, las estaciones deberían ser las más céntricas, ya que ahí el efecto del carril bici y las restricciones de acceso deberían hacerse más notables. Observaremos las siguientes estaciones:

+ Avda. Francia
+ Bulevard Sud
+ Valencia Centro
+ Olivereta

```{r}
datos_mensuales <- datos[c("Fecha","SO2","NO2","Estacion")] %>%
  filter(Estacion %in% c("Avda. Francia","Bulevard Sud", "Valencia Centro", "Olivereta")) %>%
  mutate(ano = year(Fecha), mes = month(Fecha)) %>%
  arrange(Fecha) %>%
  group_by(ano, mes) %>%
  summarise(media_SO2 = mean(SO2, na.rm=TRUE), media_NO2 = mean(NO2,na.rm=TRUE), .groups="drop")

ggplot(data = datos_mensuales, aes(x = mes, y = media_SO2, group = ano, color = factor(ano))) +
  geom_line() +
  labs(x = "Mes", y = "Media SO2", title = "Media Mensual SO2 por Año") +
  scale_color_discrete(name = "Año") +
  scale_x_continuous(breaks = 1:12, labels = month.abb, limits = c(1, 12)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplot(data = datos_mensuales, aes(x = mes, y = media_NO2, group = ano, color = factor(ano))) +
  geom_line() +
  labs(x = "Mes", y = "Media NO2", title = "Media Mensual NO2 por Año") +
  scale_color_discrete(name = "Año") +
  scale_x_continuous(breaks = 1:12, labels = month.abb, limits = c(1, 12)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Si bien no se observan cambios significativos en los niveles de SO2, en los niveles de NO2 sí que podemos observar una evolución.

