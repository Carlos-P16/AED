---
title: "ProyectoAED2023"
author: "Carlos, Diego, Miguel"
date: "2023-11-02"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introducción

En el presente informe planteamos el análisis exploratorio de un conjunto de datos sobre la calidad del aire de la ciudad de Valencia entre 2004 y 2022. El dataset empleado continene observaciones obtenidas de distintas estaciones de la red de vigilancia de Valencia. Las observaciones están compuestas por variables respectivas a diversas moleculas y elementos presentes en el aire junto a otras de tipo meteorológico como la velocidad del viento, la temperatura, etc.

El procedimiento a seguir comenzará con la correcta importación del dataset, a lo que seguirá la preparación de los datos para resolver las preguntas planteadas. Se escogerán las variables de interés y los periodos temporales sobre los que se realizará el análisis, se aplicarán las transformaciones necesarias sobre las variables, se reestructurará el dataset acorde a nuestras necesidades y se gestionarán los outliers y datos faltantes.

Una vez preparado el dataset, procederemos a responder a las preguntas planteadas mediante diversas metodologías. Todo el proceso irá acompañado de las explicaciones pertinentes y finalizaremos con una conclusión del trabajo realizado.



# Objetivos

El objetivo principal de este trabajo es familizarse con las herramientas y metodologías aprendidas para la carga, manipulación y análisis exploratorio de un conjunto de datos. 

+ analisis univariante, bivariante, NA, outliers

Para ello se van a plantear una serie de objetivos es forma de preguntas que requerirán la aplicación de las herramientas y metodologías aprendidas:

+ ¿?Influencia del cambio en el tráfico hacia el centro de la ciudad en los últimos años. (carriles bici) : Comprobar posible reducción de gases emitidos por vehículos a motor en las estaciones más céntricas.

+ ¿?Existe alguna correlación entre la calidad del aire y el día de la semana/año

+ ¿?Existe cierta evolución de la contaminación sonora (años/zonas)

+ ¿?Existe cierta evolución de la temperatura (A medias, se puede hacer algo más o incluso relacionarlo con las precipitaciones. No se me ocurre cómo pero se le podría dar una vuelta)

+ ¿?Existe cierta evolución de la contaminación. Como medir la contaminación (Falta esta)

A lo largo del desarrollo del proyecto se irán planteando y resolviendo las preguntas anteriores junto a su razonamiento y conclusiones.



# Carga de librerías y datos

```{r}
library(readr) # Carga de datos
library(lubridate) # Manejo de datos
library(tidyr) # Manejo de datos
library(dplyr) # Manejo de datos
library(ggplot2) # Visualización de datos
library(plotly) # Visualización de datos interactiva
library(stats)
```

# Importación de los datos

El primer paso es importar nuestro dataset. Para ello, en primer lugar abrimos (por ejemplo en un bloc de notas) el archivo _rvvcca.csv_ localizado en la carpeta data. De esta forma vemos el formato en el que están guardados los datos, lo cuál es importante para su correcta importación. Por ejemplo, vemos que el separador de las variables es ';', lo cuál debe ser especificado en la función _read.csv()_ ya que esta toma por defecto espera ',' como separador. Tembién definimos el formato con el que queremos importar ciertas columnas, como pueden ser las columnas de tipo fecha o algunos factores.

```{r}
# Especificamos el tipo de columna para que los datos se importen directamente con un formato adecuado
column_types <- cols(
  Fecha = col_date(format = "%Y-%m-%d"),
  `Dia de la semana` = col_factor(levels = c("Lunes", "Martes",  "Miercoles", "Jueves", "Viernes", "Sabado", "Domingo")),
  `Dia del mes` = col_factor(levels = as.character(1:31)),
  Estacion = col_factor(),
  `Fecha creacion`= col_date(format = "%Y-%m-%d"),
  `Fecha baja`= col_date(format = "%Y-%m-%d"))

# importación del dataset
datos <- read_delim("data/rvvcca.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE, col_types = column_types)
head(datos)
```

La página de donde se obtuvo el dataset no presentaba ninguna explicación de las variables, pero podemos extraer las siguientes conclusiones:

- *Id* es un identificador para cada una de las filas y no aporta ninguna información concreta.

- *Fecha* es una variable tipo *Date* que nos proporciona la fecha en la que se tomaron los datos que componen la observación. Tomaremos esta variable para la ordenación ascendente de los datos.

```{r}
datos <- arrange(datos,datos$Fecha)
```

- *Dia_de_la_semana* y *Dia_del_mes* son variables de tipo factor que indican en que día de la semana y en qué dia del mes se realiza la medida. Puede ser extraído a partir de *Fecha* usando las funciones _wday()_ y _day()_, de la librería _lubridate_.

- *Estacion* es una variable de tipo factor cuyos niveles son las distintas estaciones meteorológicas donde se tomaron las mediciones de las variables numéricas, haciendo un total de 13 estaciones.

```{r}
unique(datos$Estacion)
```

- *PM1, PM2.5, PM10* son variables de tipo numérico con datos sobre la concentración de materiales particuldos (OM) de menos de 1, 2.5 y 10 micrómetros de diámetro respectivamente.

- *NO, NO2, NOx, O2, SO2, CO, NH3* son variables con datos sobre la concentración de estas moléculas inorgánicas consideradas contaminantes en el aire. Respecto a los oxidos de nitrogeno (NOx), estos son un grupo de gases compuestos por oxigeno y nitrogeno, es decir, NO y NO2 forman parte de este grupo y por lo tanto los valores de las variables estarán altamente correlados.

- *C7H8, C6H6, C8H10* son variables con datos sobre la concentración de estas moléculas orgánicas también consideradas contaminantes en el aire.

- *Velocidad_del_viento, Direccion_del_viento, Temperatura, Humidad_relativa, Presion, Radiacion_solar, Precipitacion, Velocidad_maxima_del_viento* son variables numéricas con mediciones de estas distintas condiciones ambientales al momento de medir las concentraciones de moléculas contaminantes en el aire. Es interesante contar con estos datos para ver si influyen en los valores de contaminación.

- *As, Ni, Cd, Pb, B(a)p* son variables numéricas con datos de otras concentraciones de gases y metales contaminantes en el aire. Todos estas variables presentaban el prefijo (ng/m3) indicando las unidades en que se mide sus concentraciones. El resto de datos de concentraciones no presentan las unidades lo cuál nos hace sospechar que auiás los datos de estas variables fueron unidos a este dataset a posteriori.

- *Fecha_creación* y *Fecha_baja* son variables de tipo *Date* que parecen estar relacionadas con la creacion del dataset y que no parecen aportar información sobre nuestros datos.

```{r}
unique(datos$Fecha_creacion)
unique(datos$Fecha_baja)
```

 *Fecha_creación* solo presenta dos entradas distintas y *Fecha_baja* sólo presenta NA's por lo que estas variables parecen prescindibles`

Para evitar posibles problemas, renombramos las varianles con espacios en su nombre para trabajar sin comillas ' ' y eliminamos el sufijo (ng/m³) de algunas variables

```{r}
colnames(datos) <- gsub(x = colnames(datos), pattern=' ', replacement = '_')
colnames(datos) <- gsub(x = colnames(datos), pattern='_[(]ng[/]m³[)]$', replacement = '')
```

Vamos a mantener sólo las variables que aporten alguna información relevante:
```{r}
datos <- datos %>% select(-c('Id', 'Dia_de_la_semana','Dia_del_mes','Fecha_creacion', 'Fecha_baja'))
```


# Análisis de datos faltantes y especiales

En esta sección, previamente al análisis univariante y bivariante de las variables, vamos a realizar un análisis de la estructura del dataset. El dataset parece estar compuesto por la unión de un conjunto datasets, posiblemente por las distintas estaciones de las que provienen los datos. Con el objetivo de obtener un conjunto de datos consistente, analizaremos el porcentaje de NA's que hay por cada variable, luego veremos que datos proporcionan las estaciones y con que frecuencia, también comprobaremos cuando comenzaron a generar datos las estaciones y durante que periodos de tiempo se han obtenido las variables. 

En primer lugar vamos reemplazar todos los posibles valores especiales (NULL, NaN, Inf...)  que pudieran haber en las varianles numéricas de nuestro dataset por NA's. De esta forma podemos tratar todos estos datos que no tienen sentido a la vez.

```{r}
variables_numericas <- colnames(datos[sapply(datos,is.numeric)])
reemplazo_especiales <- function(x){
  return(ifelse(is.finite(x), x, NA))
}
datos <- mutate(datos, across(all_of(variables_numericas), reemplazo_especiales))
```

A continuación vamos a calcular el porcentaje de NA's que tiene cada variable.

```{r}
porc_na <- function(x){
  100*sum(is.na(x))/length(x)
}
datos %>% 
  summarise(across(.cols = all_of(colnames(datos)), .fns = porc_na)) %>% 
  pivot_longer(cols = all_of(colnames(datos)), names_to = 'Variable', values_to = "Porcentaje NA's") %>%
  arrange(desc(`Porcentaje NA's`)) %>% 
  mutate(`Porcentaje NA's`=round(`Porcentaje NA's`, digits = 2))
```

Vemos como la variable B(a)p está casi vacía (sólo tiene una entrada) y hay varias variables con un porcentaje de NA's por encima del 90% y muchas otras por encima del 50%. Esto quizá sea debido a que algunas variables se empezaron a medir más tarde que otras o a que no en todas las estaciones se miden todas las variables.

A continuación creamos un mapa de calor para comprobar que variables se miden en cada estación y con que frecuencia.

```{r}
num_entradas <- function(x){
  sum(!is.na(x))
}
est_var <- datos %>% 
  group_by(Estacion) %>% 
  summarise(across(.cols = all_of(variables_numericas), .fns = num_entradas)) %>% 
  pivot_longer(cols = all_of(variables_numericas), names_to = 'Variable', values_to = "Numero_entradas") %>%
  mutate(Variable = factor(Variable, levels = variables_numericas, ordered = T)) %>% 
  arrange(match(Variable, variables_numericas))

p <- ggplot(data = est_var, aes(x = Estacion, y=Variable, fill = Numero_entradas)) + 
  geom_tile() + scale_fill_gradient(low = "white", high = "blue") + 
  theme(axis.text.x=element_text(angle=45, hjust=1))

plotly::ggplotly(p)
```

En este mapa de calor podemos ver qué variables mide cada estación meteorológica, además de la cantidad de datos que aporta cada una de ellas sobre cada varaible numérica. Vemos como sólo hay dos estaciones (Viveros y Boulevard Sud) que miden las variables *As*, *Pb*, *Ni* y *Cd* y que su número de entradas es bajo en comparación con otras variable, quizá debido a que se empezaron a tomar datos de estas variables más tarde que el resto. En el caso del *NH3* vemos que solo se ha medido en la estación Boulevard Sud. Las moléculas orgánicas *C8H10*, *C6H6*, *C7H8* sólo se miden en las estaciones de Pista de Silla y Viveros. Cabe destacar también que las estaciones que miden mayor cantidad de variables son Pista de Silla, Viveros y Boulevard Sud. Por otro lado, estaciones como Conselleria Meteo y Nazaret Meteo sólo miden las condiciones ambientales y no las concentraciones de contaminantes, al igual que la estación del Puerto de Valencia con la diferencia que en esta además se miden los niveles de partículas *PM10* y de *SO2*. Además, vemos como en la estación de Valencia Olivereta sólo se miden niveles de partículas *PM2.5*, *PM10* y óxidos de nitrógeno.

Ahora queremos ver qué estaciones han estado activas a lo largo de los años:

```{r}
datos %>% 
  mutate(ano = factor(year(Fecha))) %>% 
  ggplot(aes(x=ano, fill = Estacion)) + 
  geom_bar() + 
  labs(x = 'Año') + 
  theme(axis.text.x=element_text(angle=45, hjust=1))
```

Como podemos ver, desde 2004 hasta 2007 sólo tenemos datos de las estaciones de Pista de Silla y Viveros, que se mantienen actvas hasta 2022. Posteriormente, en los siguientes 5 años (2008-2012) se van añadiendo datos de otras estaciones como la del Politécnico, Av. de Francia, Molí del Sol, Boulevard Sur, Valencia Centro y Conselleria a razón casi de una nueva estación al año y que se mantienen hasta el final (2022). Desde 2013 hasta 2016 se siguen viendo las mismas estaciones y en los siguientes dos años (2017-2018) se añaden datos de la estación del Puerto de Valencia, de la que posteriormente dejamos de obtener datos. Finalmente, desde 2019 hasta 2022 se van añadiendo progresivamente cada año las estaciones de Nazaret, Puerto Molí Trans. Ponent, Puerto antic Turia y Valencia Olivereta. 2022 es el año donde tenemos datos de más estaciones distintas.

A continuación queremos visualizar el período de tiempo entre la primera y la última medida de cada variable

```{r}
datos %>% 
  pivot_longer(cols = all_of(variables_numericas), names_to = 'Variables', values_to = 'valor', values_drop_na = T) %>% 
  mutate(Variables = factor(Variables, levels = variables_numericas, ordered = T)) %>% 
  ggplot(aes(x=Fecha, y=valor, color = Variables)) + 
  geom_line() + 
  facet_wrap(Variables~., scales = "free_y") + 
  theme(legend.position = "none") + 
  theme(axis.text.x=element_text(angle=45, hjust=1), axis.text.y = element_blank(), axis.ticks.y = element_blank()) + 
  labs(y = '') + 
  scale_colour_manual(values = rainbow(26)) 
```

A partir de este gráfico podemos ver como algunas variables empiezan a ser medidas a partir de cierta fecha. En concreto, los datos de *As*, *Cd*, *Ni*, *Pb* empiezan a tomarse sólo a partir de 2019. Además, terminan antes que el resto de variables, a principios del 2022.. Otras variables como *Precipitacion*, *Velocidad_maxima_del_viento*,*PM1* o *NH3* empiezan a tener datos un poco más tarde que el resto pero antes del 2019. Todas las demás variables presentan almenos algún dato en 2004.

Tras esta primera visualización de nuestros datos, podemos concluir que la gran cantidad de datos faltantes se debe a una combinación del hecho de que no todas las estaciones miden todas las variables, sumado a que los datos de ciertas variables se empiezan a medir posteriormente que el resto. Esto puede deberse a que la(s) estación(es) que recoge(n) datos de esta variable comienza(n) a funcionar en una fecha posterior al resto de estaciones o simplemente debido a que hasta cierto año no se instalan sensores en las estaciones para medir esas variables. En cualquier caso, dependiendo del análisis que se quiera realizar se habrán de escoger unas variables, y por ende un determinado número de estaciones que midan estas variables y un período de tiempo en que se estén recogiendo datos de estas variables.

En nuestro caso vamos a escoger un período de 10 años, desde 2012 a 2022, ya que en este período de tiempo hay un número significativo de estaciones recogiendo datos y la mayoría de las variables son medidas en este intervalo de tiempo de forma consistente. No obstante, decidimos descartar las variables *Pb*, *Cd*, *Ni*, *As*, *B(a)p* y *NH3* debido a que se comienzan a medir después del 2012 y resultaría poco razonable imputar los datos de estas variables en esos años. De la misma forma, también descartamos las variables *C7H8*, *C6H6*, y *C8H10* debido a que presentan grandes períodos de tiempo con ausencia de datos intercalados entre 2012 y 2022, por lo que también sería poco razonable imputar estos datos. 

# Análisis univariante

En esta sección analizaremos las variables de forma individual con el objetivo de conocer sus magnitudes, es decir, las unidades de medida que representan, y como se distribuyen. Como se ha mencionado previamente, escogemos los datos que comienzan en 2012, concretamente cunado se empiezan a tomar datos de la precipitación, y los datos previos a 2023, concretamente cuando se dejan de tomar los oxidos de nitrogeno.

Variables de interés
  - Fecha
  - Estación
  - Gases: NO, NO2, NOx, SO2, CO, O3 
  - Meteorológicas: Temperatura, Humedad, Presion, Velocidad viento, Direccion viento, Radiación solar, Precipitación
  - Calidad de vida: Ruido

Comenzamos con un summary de las variables numéricas para analizar las magnitudes de las variables y como se distribuyen los datos.

```{r}
variables <- c("Fecha", "Estacion","NO", "NO2", "NOx", "SO2", "CO", "O3", "Temperatura", "Velocidad_del_viento", "Direccion_del_viento", "Humidad_relativa", "Presion", "Radiacion_solar", "Precipitacion","Ruido")

mystats <- function(x, na.omit=TRUE){
                if (na.omit)
                    x <- x[!is.na(x)]
                min <- min(x)
                Q1 <- quantile(x, 0.25)
                median <- median(x)
                mean <- mean(x)
                dt <- sd(x)
                Q3 <- quantile(x, 0.75)
                max <- max(x)
                
                n <- length(x)
                IQR <- IQR(x)
                
                return(round(c(min=min, Q1=Q1, median=median, mean=mean, dt=dt, Q3=Q3, max=max, n=n, IQR=IQR),2))
} 

precipitacion <- datos[,c('Fecha','Precipitacion')] %>% na.omit
fecha_inicio <- precipitacion$Fecha[1]
oxidos_n <- datos[,c('Fecha','NOx')] %>% na.omit
fecha_fin <- oxidos_n$Fecha[nrow(oxidos_n)]

datos <- datos[datos$Fecha > fecha_inicio & datos$Fecha < fecha_fin, variables]

sapply(datos[-c(1,2)], mystats)
```

Mediante el summary anterior podemos averiguar cuales son las unidades de medida empleadas contrastando con información externa, ya que en la fuente de los datos no se proporcionan.

  - Gases (NO, NO2, NOx, SO2, CO, O3): microgramos por metro cubico ($\mu$g/m3)
  - Temperatura: grados centígrados (Cº)
  - Humedad: porcentaje (%)
  - Presión: hectopascales (hPa)
  - Velocidad del viento: kilometros/hora (m/s)
  - Dirección del viento: ángulo de 0 a 360 (º)
  - Precipitación: litros de agua por metro cuadrado (mm)
  - Radiación solar: Vatios por metro cuadrado (W/m2)


Densidades:

```{r}
# Gases
datos[2:8] %>%
  pivot_longer(cols = 2:7, names_to = 'Variables', values_to = 'valor', values_drop_na = T) %>%
  ggplot(aes(x=valor)) + 
  geom_histogram(aes(y=stat(density), fill='blue', alpha=0.6), bins=50) +
  geom_density() +
  facet_wrap(~Variables, scales = "free") + 
  theme(legend.position = "none")
```

```{r}
# Gases
datos[c(2,c(9:15))] %>%
  pivot_longer(cols = 2:8, names_to = 'Variables', values_to = 'valor', values_drop_na = T) %>%
  ggplot(aes(x=valor)) + 
  geom_histogram(aes(y=stat(density), fill='blue', alpha=0.6), bins=50) +
  geom_density() +
  facet_wrap(~Variables, scales = "free") + 
  theme(legend.position = "none")
```


# Detección y eliminación de outliers con métodos univariante

A continuación, procederemos a detectar y eliminar outliers.

```{r}
tresSigma <- function(x){
  media <- mean(x,na.rm=TRUE)
  desviacion <- sd(x,na.rm=TRUE)
  lim_low <- media - 3 * desviacion
  lim_upp <- media + 3 * desviacion
  
  outliers <- x[x < lim_low | x > lim_upp]
  
  return(outliers)
}

hampel <- function(x){
  mediana <- median(x, na.rm = TRUE)
  madm <- mad(x, constant = 1.4826, na.rm = TRUE)
  umbral <- 3 * madm
  
  outliers <- x[abs(x-mediana) > umbral]
  
  return(outliers)
}

boxplot <- function(x){
  q1 <- quantile(x, 0.25, na.rm = TRUE)
  q3 <- quantile(x, 0.75, na.rm = TRUE)
  
  iqr <- q3 - q1
  
  lower_limit <- q1 - 1.5 * iqr
  upper_limit <- q3 + 1.5 * iqr
  
  outliers <- x[x < lower_limit | x > upper_limit]
  
  return(outliers)
}

percentil <- function(x){
  p5 <- quantile(x, 0.05, na.rm = TRUE)
  p95 <- quantile(x, 0.95, na.rm = TRUE)
  
  outliers <- x[x < p5 | x > p95]
  
  return(outliers)
}

remove_outliers <- function(x, func) {
  outliers <- func(x)
  return(x[!is.na(outliers)])
}

replace_outliers <- function(x, func) {
  outliers <- func(x)
  x[outliers] <- NA
  return(x)
}
```

Vamos a comprobar el funcionamiento de los métodos de detección de outliers. Lo aplicaremos sobre todas las variables numéricas.
```{r}
columnas_numericas <- names(datos)[3:15]

m1 <- apply(datos[columnas_numericas], 2, tresSigma)
m2 <- apply(datos[columnas_numericas], 2, hampel)
m3 <- apply(datos[columnas_numericas], 2, boxplot)
m4 <- apply(datos[columnas_numericas], 2, percentil)

m1 <- sapply(sapply(m1, complete.cases),sum)
m2 <- sapply(sapply(m2, complete.cases),sum)
m3 <- sapply(sapply(m3, complete.cases),sum)
m4 <- sapply(sapply(m4, complete.cases),sum)

resultados <- data.frame(
  Metodo = rep(c("3-Sigma", "Hampel", "Boxplot", "Percentil"), each = length(columnas_numericas)),
  Columna = rep(columnas_numericas, times = 4),
  Outliers_Detectados = c(m1, m2, m3, m4)
)

ggplot(resultados, aes(x = Columna, y = Outliers_Detectados, fill = Metodo)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(title = "Número de Outliers Detectados por Método",
       x = "Columna Numérica",
       y = "Número de Outliers Detectados") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Usaremos el metodo de Hampel, ya que por la naturaleza de los datos no podemos suponer los datos como una distribución Gaussiana.

A continuación, reemplazaremos los outliers por NA.

```{r}
datos_no_outliers <- datos %>%
  mutate_at(vars(all_of(columnas_numericas)), ~ replace_outliers(., hampel))
```

# Analisis bivariante

Partiendo de las conclusiones obtenidas en el apartado de análisis de datos faltantes, nos parece interesante ver si existe alguna influencia en el valor de la variable por parte de la estación de la que proviene. En caso de no existir una influencia considerable podemos utilizar los valores obtenidos en otras estaciones para imputar otros. Finalmente comprobaremos si año influye en el valor de la variable, para ver si a lo largo del tiempo ha ocurrido algún cambio considerable.

Mediante boxplots vamos a analizar como se distribuyen los datos respecto a las estaciones. En primer lugar los gases:

```{r}
# Gases
datos_no_outliers %>%
  select(all_of(variables[2:8])) %>%
  pivot_longer(cols = 2:7, names_to = 'Variables', values_to = 'valor', values_drop_na = T) %>%
  ggplot(aes(y=valor, fill=Estacion)) + 
  geom_boxplot(outlier.size = 1) +
  facet_wrap(~Variables, scales = "free_y") + 
  theme(axis.text.x = element_blank(), legend.position = "none")
```

En segundo lugar las variables meteorológicas:

```{r}
# Variables meteorológicas
# Gases
datos_no_outliers %>%
  select(all_of(variables[c(2,c(9:15))])) %>%
  pivot_longer(cols = 2:8, names_to = 'Variables', values_to = 'valor', values_drop_na = T) %>%
  ggplot(aes(y=valor, fill=Estacion)) + 
  geom_boxplot(outlier.size = 1) +
  facet_wrap(~Variables, scales = "free_y") + 
  theme(axis.text.x = element_blank(), legend.position = "none")
```

Podemos concluir con que generalmente la estación no influye en los valores de las variables. Esta información nos es útil para la imputación de NA's, ya que podemos emplear la media de las medidas obtenidas por otras estaciones.

Ahora vamos a ver una sencilla evolución mediante boxplots de el valor de las variables a lo largo de los años. Comenzamos con los gases:

```{r}
# Gases
datos_no_outliers %>%
  select(all_of(variables[c(1,3:8)])) %>%
  mutate(ano = factor(year(Fecha))) %>%
  pivot_longer(cols = 2:7, names_to = 'Variables', values_to = 'valor', values_drop_na = T) %>%
  ggplot(aes(y=valor, fill=ano)) + 
  geom_boxplot(outlier.size = 1) +
  facet_wrap(~Variables, scales = "free_y") + 
  theme(axis.text.x = element_blank(), legend.position = "none")
```

Se puede apreciar una leve reducción a lo largo de los años de los gases considerados como contaminantes a excepción del SO2 que parece mantenerse constante. Por otro lado vemos un leve aumento del ozono (O3), por lo que podría existir una relación con la disminución de gases contaminantes. Continuamos con las variables meteorológicas:

```{r}
# Gases
datos_no_outliers %>%
  select(all_of(variables[c(1,9:15)])) %>%
  mutate(ano = factor(year(Fecha))) %>%
  pivot_longer(cols = 2:8, names_to = 'Variables', values_to = 'valor', values_drop_na = T) %>%
  ggplot(aes(y=valor, fill=ano)) + 
  geom_boxplot(outlier.size = 1) +
  facet_wrap(~Variables, scales = "free_y") + 
  theme(axis.text.x = element_blank(), legend.position = "none")
```

Como era de esperar, las variables meteorológicas no han sufrido variaciones a lo largo de los años.


# Imputación de NA's

Centrándonos en las variables de interés, si bien son más consistentes en lo que se refiere a las entradas diarias de cada variable, todavía hay muchos datos faltantes. No obstante, podemos aprovechar el hecho de que los datos diarios de las variables en todas las estaciones de Valencia suelen ser muy parecidos, por lo que decidimos imputar los datos faltantes en cada día con la media de esta variable sobre todas las estaciones. Tras realizar esta imputación, todavía hay algunas variables que presentan NA's, esto se debe a que hay algunos días donde donde esta variable no se ha medido en ninguna de las estaciones. Esto sólo ocurre en el 11% de las observaciones, por lo que decidimos desprendernos de estas observaciones, ya que el volúmen de datos es suficientemente grande y los datos todavía pueden considerarse diarios.

```{r}
imputacion_NAs <- function(x){
  ifelse(is.na(x), mean(x, na.rm = T), x)
}

datos_limpios <- datos_no_outliers %>% 
  # Esta hecho arriba
  #filter(Fecha >= as.Date('2012-01-01', format = '%Y-%m-%d'), Fecha <= as.Date('2022-01-01', format = '%Y-%m-%d')) %>%
  #select(-c('Pb_(ng/m3)','Cd_(ng/m3)','Ni_(ng/m3)','As_(ng/m3)','B(a)p_(ng/m3)','NH3','C7H8','C6H6','C8H10')) %>% 
  group_by(Fecha) %>% 
  mutate(across(.cols = all_of(columnas_numericas), imputacion_NAs)) %>% 
  mutate(across(all_of(columnas_numericas), reemplazo_especiales)) %>%
  ungroup

100*sum(complete.cases(datos_limpios))/nrow(datos_limpios)

datos_limpios <- datos_limpios[complete.cases(datos_limpios),]
```

# Analisis bivariante 2 (tras imputación de NA)

## Correlaciones

```{r, eval=FALSE}
library(GGally)

# Correlacion Pearson
corr1_P <- datos[3:15] %>%
  na.omit %>%
  cor

corr2_P <- datos_limpios[3:15] %>%
  na.omit %>%
  cor
corr2_P

# Ver diferencias con data raw y data con NA imputados y sin outliers univariantes
diff_P <- abs(corr1_P-corr2_P)
diff_P

# Correlacion Spearman
corr1_S <- datos[3:15] %>%
  na.omit %>%
  cor(method = 'spearman')

corr2_S <- datos_limpios[3:15] %>%
  na.omit %>%
  cor(method = 'spearman')
corr2_S

diff_S <- abs(corr1_S-corr2_S)
diff_S

ggcorr(datos_limpios[3:15])

#ggpairs(datos_limpios[3:15])
```
Basándonos en las observaciones, podemos extraer las siguientes conclusiones:

+ Existe una correlación negativa importante entre NOs y Ozono. Esto podría deberse a que la presencia de óxidos de nitrógeno puede contribuir a la degradación del ozono en la atmósfera, lo que tiene implicaciones para la calidad del aire y la contaminación.

+ Correlación positiva de NOx con el resto de NO (NO, NO2...). Esto se mencionó con anterioridad en la memoria.

+ Correlación positiva entre Temperatura y Radiación Solar. Esto es coherente con las estaciones más cálidas que a menudo experimentan más horas de sol y mayor radiación solar.

+ Correlación entre Radiación Solar y Ozono. Esto tiene sentido ya que la capa de ozono filtra la mayor parte de la radiación ultravioleta proveniente del sol, por lo tanto están muy relacionados entre ellos.

## Detección y eliminación de outliers con métodos multivariable

En este apartado, trabajaremos con el dataframe de datos que contiene la imputación de NA.

```{r}
distancia_mahalanobis <- function(x) {
  media = colMeans(x)
  S = cov(x)
  
  dist = mahalanobis(x,media,S)
  umbral <- qchisq(0.95, df = ncol(x))

  outliers <- which(dist > umbral)
  
  return(outliers)
}

instancias_outliers <- distancia_mahalanobis(datos_limpios[columnas_numericas])
paste0("La distancia de mahalanobis detecta como outliers ", length(instancias_outliers)," datos con una confianza del 95%. Con estos datos, lo que haremos no es cambiarlos por NA (pues miramos sobre instancias enteras), sino que directamente las eliminaremos.")

datos_limpios_sin_outliers <- datos_limpios[-instancias_outliers,]
```

## Variables más y menos correlacionadas

La correlación puede tener valores en el rango [-1,1]. Siendo -1 el indicador de un comportamiento absolutamente contrario y siendo 1 la misma variable, pues tiene exactamente el mismo comportamiento.

A continuación, observaremos en orden descendente las correlaciones de variables superiores a 0'7. Además, también observaremos las correlaciones menores de 0'7 en orden descendente.

Esto puede darnos información para reflexionar sobre la naturaleza y comportamiento de los datos.

```{r}
library(GGally)
#columnas_numericas_limpias <- setdiff(columnas_numericas,c('Pb','Cd','Ni','As','B(a)p','NH3','C7H8','C6H6','C8H10'))
df <- cor(na.omit(datos_limpios[3:15])) %>%
  as.data.frame(.)

df$Variable1 <- rownames(df)

cor <- df %>%
  pivot_longer(cols = -Variable1, names_to = "Variable2", values_to = "Correlation")

correlaciones <- cor[cor$Correlation > 0.7,] %>% arrange(desc(Correlation)) %>% filter(Variable1 != Variable2)
correlaciones_inversas <- cor[cor$Correlation < -0.7,] %>% arrange(Correlation) %>% filter(Variable1 != Variable2)
paste0("El numero total de correlaciones inversas es ",nrow(correlaciones_inversas),". Por lo tanto, solo estudiaremos las correlaciones directas")

ggplot(correlaciones, aes(x = Variable1, y = Variable2, color = Correlation)) +
  geom_tile(aes(fill = Correlation)) +
  theme_minimal() +
  labs(title = "Correlaciones Positivas")

ggcorr(datos_limpios[3:15])
```


# Influencia de carril bici

Para estudiar la influencia de un carril bici por el centro de Valencia, estudiaremos la evolución de gases contaminantes en diversas estaciones de la ciudad. Mediremos la evolución de los gases:

+ SO2: Originado sobre todo durante la combustión de carburantes fósiles.
+ NO2: Es un contaminante atmosférico cuyas fuentes fundamentales son el tráfico rodado, así como las emisiones de determinadas industrias y grandes instalaciones de combustión.

Además, las estaciones deberían ser las más céntricas, ya que ahí el efecto del carril bici y las restricciones de acceso deberían hacerse más notables. Observaremos las siguientes estaciones:

+ Avda. Francia
+ Bulevard Sud
+ Valencia Centro
+ Olivereta


```{r}
datos_mensuales <- datos[c("Fecha","SO2","NO2","Estacion")] %>%
  filter(Estacion %in% c("Avda. Francia","Bulevard Sud", "Valencia Centro", "Olivereta")) %>%
  mutate(ano = year(Fecha), mes = month(Fecha)) %>%
  arrange(Fecha) %>%
  group_by(ano, mes) %>%
  summarise(media_SO2 = mean(SO2, na.rm=TRUE), media_NO2 = mean(NO2,na.rm=TRUE), .groups="drop")

ggplot(data = datos_mensuales, aes(x = mes, y = media_SO2, group = ano, color = factor(ano))) +
  geom_line() +
  labs(x = "Mes", y = "Media SO2", title = "Media Mensual SO2 por Año") +
  scale_color_discrete(name = "Año") +
  scale_x_continuous(breaks = 1:12, labels = month.abb, limits = c(1, 12)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplot(data = datos_mensuales, aes(x = mes, y = media_NO2, group = ano, color = factor(ano))) +
  geom_line() +
  labs(x = "Mes", y = "Media NO2", title = "Media Mensual NO2 por Año") +
  scale_color_discrete(name = "Año") +
  scale_x_continuous(breaks = 1:12, labels = month.abb, limits = c(1, 12)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

NOTA: El gráfico de NO2 se ve mucho mejor la reducción cuando se observan todas las estaciones.

Si bien no se observan cambios significativos en los niveles de SO2, en los niveles de NO2 sí que podemos observar una evolución.

Respecto al NO2 si que se puede apreciar una reducción a lo largo de los años. Con unos niveles más bajos especialmente en los últimos 3 años. Además se puede apreciar una periodicidad, concretamente una reducción de los niveles de NO2 en los meses de verano. Esto coincide con el momento del año donde menos gente vive en la ciudad y por lo tanto menos tráfico hay. En conclusión parece que las medidas de transporte que se han tomado en la ciudad han influenciado en la reducción de gases contaminantes.

# Relación entre la calidad del aire y el dia de la semana

Aqui observamos si, en general la calidad del aire se ve influenciada por el día de la semana. Queremos sobre todo fijarnos en la distinción entre días laborables y de descanso. Podemos comprobar cómo, efectivamente, existe una disminución en los gases contaminantes los días festivos con respecto a los días laborables.

```{r}
gases_interes <- c("NO","NO2","NOx","SO2","CO")

datos_semanales <- datos_limpios %>%
  mutate(Dia_de_la_semana = factor(wday(Fecha))) %>%
  filter(!(Dia_de_la_semana %in% c(1,6))) %>%
  select(gases_interes) %>%
  summarise_all(.funs = list(mean)) %>%
  pivot_longer(cols=everything(),names_to = "Gas",values_to="Valor")

datos_festivos <- datos_limpios %>%
  mutate(Dia_de_la_semana = factor(wday(Fecha))) %>%
  filter(Dia_de_la_semana %in% c(1,6)) %>%
  select(gases_interes) %>%
  summarise_all(.funs = list(mean)) %>%
  pivot_longer(cols=everything(),names_to = "Gas",values_to="Valor")

datos_combinados <- rbind(
  transform(datos_semanales, Tipo = "Semanal"),
  transform(datos_festivos, Tipo = "Festivo")
)

ggplot(datos_combinados, aes(x = Gas, y = Valor, fill = Tipo)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(title = "Valores de Gases Semanales y Festivos",
       x = "Gas",
       y = "Valor") +
  scale_fill_manual(values = c("Semanal" = "blue", "Festivo" = "red")) +
  theme_minimal() +
  theme(legend.title = element_blank())
```

# Evolución de la contaminación sonora a lo largo de los años

Podemos observar un incremento visibleen la medición del ruido medio a lo largo de los años. Obviamente, en los datos del 2020 podemos observar un decrecimiento de los mismos, pero vemos cómo continúa aun así subiendo.

```{r}
datos_ruido <- datos_limpios[c("Fecha","Ruido")] %>%
  mutate(Ano = year(Fecha)) %>%
  select(-Fecha) %>%
  group_by(Ano) %>%
  summarize(Media_Ruido = mean(Ruido, na.rm = TRUE, .groups = "drop"))

ggplot(datos_ruido, aes(x = Ano, y = Media_Ruido)) +
  geom_line() +
  labs(x = "Año", y = "Media de Ruido") +
  theme_minimal() +
  scale_y_continuous(limits = c(min(datos_ruido$Media_Ruido), max(datos_ruido$Media_Ruido)))
```

Ahora comprobaremos si este ruido medido depende de la zona dónde la midamos. Para ello, vamos a observar el comportamiento de la varianza de la media de los ruidos agrupados por estaciones. Calcularemos la desviación para cada año y, finalmente, la media de todas las desviaciones Si el valor es pequeño, entonces podemos afirmar que el incremento en el ruido no es de ciertas zonas, sino generalizado.

```{r}
datos_ruido_estaciones <- datos_limpios[c("Fecha","Estacion","Ruido")] %>%
  mutate(Ano = year(Fecha)) %>%
  select(-Fecha) %>%
  group_by(Ano,Estacion) %>%
  summarize(Media_Ruido = mean(Ruido, na.rm = TRUE, .groups = "drop")) %>%
  group_by(Ano) %>%
  summarize(Desviacion_por_ano = sd(Media_Ruido,na.rm=TRUE))

ggplot(datos_ruido_estaciones, aes(x = Ano, y = Desviacion_por_ano)) +
  geom_line() +
  labs(x = "Año", y = "Desviacion de ruido por estación") +
  theme_minimal() 

mean(datos_ruido_estaciones$Desviacion_por_ano)
```

Podemos observar que, para los valores que tratamos (sobre 50 y 60), una desviación del 0.3 es despreciable.

# Evolución de la temperatura a lo largo de los años

También se puede observar el aumento generalizado de la temperatura a lo largo de los años. Es curioso que, pese a que en el mundo existe un aumento generalizado de la temperatura, en Valencia estuvo bajando esta tendencia y no es hasta el año 2017 que comenzaron a subir de nuevo. Pese a lo mencionado, bastante visible el hecho de que nos encontramos en una tendencia creciente.

```{r}
datos_temperatura <- datos_limpios[c("Fecha","Temperatura")] %>%
  mutate(Ano = year(Fecha)) %>%
  select(-Fecha) %>%
  group_by(Ano) %>%
  summarize(Media_Temperatura = mean(Temperatura, na.rm = TRUE, .groups = "drop"))

ggplot(datos_temperatura, aes(x = Ano, y = Media_Temperatura)) +
  geom_line() +
  labs(x = "Año", y = "Media de Temperatura") +
  theme_minimal() +
  scale_y_continuous(limits = c(min(datos_temperatura$Media_Temperatura), max(datos_temperatura$Media_Temperatura)))
```

# Cómo se ha comportado la contaminación a lo largo de los años

Cuando contestamos a la primera pregunta, nos centramos en gases que soltaban los carburantes y solo observamos las estaciones más cercanas al centro de Valencia. En esta ocasión, estudiaremos el comportamiento de todos los gases contaminantes en todas las estaciones.

Esta vez podemos observar que se produjo un pico de todos los gases en el año 2016, pero que por lo general las medidas de estos se han mantenido bastante estables o incluso decrecientes en el tiempo.

```{r}
datos_gases <- datos_limpios[c("Fecha", "NO", "NO2", "NOx", "SO2", "CO")] %>%
  mutate(Ano = year(Fecha)) %>%
  select(-Fecha) %>%
  pivot_longer(cols = c("NO", "NO2", "NOx", "SO2", "CO"), names_to = "Gas", values_to = "Valor") %>%
  group_by(Ano, Gas) %>%
  summarize(Media = mean(Valor, na.rm = TRUE, .groups = "drop"))

ggplot(datos_gases, aes(x=Ano,y=Media,color=Gas)) + 
  geom_line() +
  labs(x = "Año") +
  theme_minimal()
```

