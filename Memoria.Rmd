---
title: ProyectoAED2023
author:
  - name: Carlos
  - name: Diego
  - name: Miguel
affiliation:
  - num: 1
    address: |
      Universidad de Valencia - 
      ETSE, UV
      Avinguda de l'Universitat, 46100 Burjassot, Valencia
    email: leutnant@fh-muenster.de
  - num: 2
# document options
journal: notspecified
type: article
status: submit
# front matter
simplesummary: |
  A Simple summary goes here.
abstract: |
  Análisis exploratorio de un conjunto de datos sobre la calidad del aire de la ciudad de Valencia entre 2004 y 2022
# back matter
keywords: |
  Contaminación, Valencia, datos, Análisis Exploratorio Datos
endnotes: false
output: 
  rticles::mdpi_article:
    extra_dependencies: longtable
---

```{r setup, include=FALSE, fig.align='left'}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, out.width = '80%')
```

# Introducción

En el presente informe planteamos el análisis exploratorio de un conjunto de datos sobre la calidad del aire de la ciudad de Valencia entre 2004 y 2022. El dataset empleado continene observaciones obtenidas de distintas estaciones de la red de vigilancia de Valencia. Las observaciones están compuestas por variables respectivas a diversas moleculas y elementos presentes en el aire junto a otras de tipo meteorológico como la velocidad del viento, la temperatura, etc.

<!-- El procedimiento a seguir comenzará con la correcta importación del dataset, a lo que seguirá un previo estudio de los datos con el objetivo de conocer la estructura del dataset y sus peculiaridades. Continuaremos con la preparación de los datos para resolver las preguntas planteadas y escogerán las variables de interés y los periodos temporales sobre los que se realizará el análisis univariante y bivariante, por otro lado también se gestionarán los outliers y datos faltantes. -->

<!-- Una vez preparado el dataset y estudiadas sus variables, procederemos a responder a las preguntas planteadas mediante diversas metodologías. Todo el proceso irá acompañado de las explicaciones pertinentes y finalizaremos con una conclusión del trabajo realizado. -->


# Objetivos

El objetivo principal de este trabajo es familizarse con las herramientas y metodologías aprendidas para la carga, manipulación y análisis exploratorio de un conjunto de datos. Como objetivos principales tenemos:

+ Analisis univariante y bivariante

+ Detección e imputación de NA's

+ Detección y gestión de outliers

Por otro lado, planteamos otros objetivos en forma de preguntas:

+ ¿Existe algún tipo de influencia sobre los niveles de gases contaminantes debido al cambio en el tráfico hacia el centro (creación carriles bici y reducción de carriles) de la ciudad en los últimos años?

+ ¿Existe alguna correlación entre la calidad del aire y el día de la semana/año?

+ ¿Existe cierta evolución de la contaminación sonora (años/zonas)?

+ ¿Existe cierta evolución de la temperatura? (A medias, se puede hacer algo más o incluso relacionarlo con las precipitaciones. No se me ocurre cómo pero se le podría dar una vuelta)

+ ¿Existe cierta evolución de la contaminación. Como medir la contaminación? (Falta esta)


# Análisis exploratorio de los datos

## Importación de los datos

```{r}
pacman::p_load(readr, lubridate, tidyr, dplyr, ggplot2, plotly, stats, kableExtra)
```

```{r}
# Tipo de las columnas
column_types <- cols(
  Fecha = col_date(format = "%Y-%m-%d"),
  `Dia de la semana` = col_factor(
    levels = c(
      "Lunes",
      "Martes",
      "Miercoles",
      "Jueves",
      "Viernes",
      "Sabado",
      "Domingo"
    )
  ),
  `Dia del mes` = col_factor(levels = as.character(1:31)),
  Estacion = col_factor(),
  `Fecha creacion` = col_date(format = "%Y-%m-%d"),
  `Fecha baja` = col_date(format = "%Y-%m-%d")
)

# Parámetros importación
datos <-
  read_delim(
    "data/rvvcca.csv",
    delim = ";",
    escape_double = FALSE,
    trim_ws = TRUE,
    col_types = column_types
  )
```

```{r}
# Renombrando variables
colnames(datos) <-
  gsub(x = colnames(datos),
       pattern = ' ',
       replacement = '_')
colnames(datos) <-
  gsub(x = colnames(datos),
       pattern = '_[(]ng[/]m³[)]$',
       replacement = '')
datos <- datos %>% rename(Vel_viento = Velocidad_del_viento, 
                          Dir_viento = Direccion_del_viento, 
                          Humedad_rel = Humidad_relativa, 
                          Max_vel_viento = Velocidad_maxima_del_viento)
```

```{r, include=FALSE}
# Sumario
levels <- function(x) {
  as.character(length(unique(x)))
}

topLevel <- function(x) {
  names(which.max(table(x)))
}

topCount <- function(x) {
  as.character(sum(as.character(x) == names(which.max(table(
    x
  ))), na.rm = T))
}

topFrec <- function(x) {
  as.character(round(sum(
    as.character(x) == names(which.max(table(x))), na.rm = T
  ) / length(x), digits = 3))
}

missFrec <- function(x) {
  as.character(round(sum(is.na(x)) / length(x), digits = 3))
}

sumario <-
  list(
    type = ~ class(.x),
    levels = ~ levels(.x),
    topLevel = ~ topLevel(.x),
    topCount = ~ topCount(.x),
    topFrec = ~ topFrec(.x),
    missFrec = ~ missFrec(.x)
  )

res <- datos %>%
  summarise(across(
    .cols = all_of(colnames(datos)),
    .fns = sumario,
    .names = "{.col}-{.fn}"
  )) %>%
  pivot_longer(cols = 1:203,
               names_to = 'variable_estadistica',
               values_to = 'valor') %>%
  separate(variable_estadistica,
           into =  c('variable', 'estadistica'),
           sep = '-') %>%
  pivot_wider(names_from = 'estadistica', values_from = 'valor')

# Resultado
anexo1 <- kableExtra::kable(res, format = "latex", 
             booktabs = TRUE, 
             caption = "Sumario variables\\label{tabla:anexo1}", 
             align = 'ccc', centering = FALSE,
             table.envir = "table", position = "H") %>%
  kableExtra::kable_styling(font_size=7)
```

<!-- El primer paso es importar nuestro dataset. Para ello, en primer lugar abrimos (por ejemplo en un bloc de notas) el archivo _rvvcca.csv_ localizado en la carpeta data. De esta forma vemos el formato en el que están guardados los datos, lo cuál es importante para su correcta importación. Por ejemplo, vemos que el separador de las variables es ';', lo cuál debe ser especificado en la función _read_delim()_ de readr que usamos para la importación. Tembién definimos el formato con el que queremos importar ciertas columnas, como pueden ser las columnas de tipo fecha o algunos factores. -->

<!-- Para evitar posibles problemas, renombramos las varianles con espacios en su nombre para trabajar sin comillas ' ', eliminamos el sufijo (ng/m³) que aparece en algunas variables y acortamos los nombres de algunas variables. -->

Para la importación de nuestro dataset fue necesario establecer ";" como el separador de las variables. Por otro lado, definimos el formato de las variables de forma previa ya que tras una exploración visual percibimos variables de tipo _factor_ y _fecha_. Con el objetivo de estudiar las características generales de nuestro dataset realizamos un sumario con el tipo de cada variable *type*, cuantos valores distintos tiene *levels*, su valor más frecuente *topLevel*, cuántas veces aparece *topCount*, y en qué proporción *topFreq* y por último la proporción de datos faltantes de cada variable *missFreq*. En el Anexo 1, en la Tabla \ref{tabla:anexo1}, encontramos las características generales obtenidas. A contrinuación explicamos cada variable:

- *Id* es un identificador para cada una de las filas y no aporta ninguna información concreta.

- *Fecha* es una variable tipo *Date* que nos proporciona la fecha en la que se tomaron los datos que componen la observación. Tomaremos esta variable para la ordenación ascendente de los datos.

```{r}
datos <- arrange(datos, datos$Fecha)
```

- *Dia_de_la_semana* y *Dia_del_mes* son variables de tipo factor que indican en que día de la semana y en qué día del mes se realiza la medida. Puede ser extraído a partir de *Fecha* usando las funciones _wday()_ y _day()_, de la librería _lubridate_. 

<!-- Vemos que el día de la semana más repetido es el Sábado y el del mes es el 31, sin embargo sus frecuecnias son prácticamente 1/7 y 1/30 por lo que parece indicar que todos los días de la semana y del mes están en la misma proporción. Esto estaría enconcordancia con el hecho de que tenemos datos realmente diarios. -->

- *Estacion* es una variable de tipo factor cuyos niveles son las distintas estaciones meteorológicas donde se tomaron las mediciones de las variables numéricas, haciendo un total de 13 estaciones. 
<!-- Las estaciones son: Pista Silla, Viveros, Politecnico, Avda. Francia, Moli del Sol, Bulevard Sud, Valencia Centro, Conselleria Meteo, Nazaret Meteo, Puerto Moll Trans. Ponent, Puerto llit antic Turia, Valencia Olivereta y Puerto Valencia  -->

<!-- La más repetida es la estación de Pista de Silla con una frecuencia de 0.16 > 1/13 = 0.077. Esto significa que es la estación que aparece en más días distintos, y es indicativo de que no todas las estaciones funcionan durante el mismo tiempo.  -->

<!-- ```{r, include=FALSE} -->
<!-- unique(datos$Estacion) -->
<!-- ``` -->

- *PM1, PM2.5, PM10* son variables de tipo numérico con datos sobre la concentración de materiales particuldos (PM) de menos de 1, 2.5 y 10 micrómetros de diámetro respectivamente.

<!-- Pese a ser variables numéricas supuestamente continuas llama a la atención que no hay un gran número de niveles distintos comparado con el número de filas del del dataset (alrededor de 10 veces menos). También vemos que hay un gran número de datos faltantes, sobre todo para PM1 (más de un 70%) y esto puede explicar en parte que no haya tantos valores distintos. Sin embargo, también podría deberse a que quizá durante muchos días el nivel de concentración de esas partículas se mantiene constante (o al menos la sensibilidad del sensor que las mide no es capaz de medir tal diferencia). La gran cantidad de datos faltantes puede deberse a que las varaibles no se miden durante ciertos períodos de tiempo o en todas las estaciones. -->

- *NO, NO2, NOx, O2, SO2, CO, NH3* son variables con datos sobre la concentración de estas moléculas inorgánicas consideradas contaminantes en el aire. Respecto a los óxidos de nitrógeno (NOx), estos son un grupo de gases compuestos por oxígeno y nitrógeno, es decir, NO y NO2 forman parte de este grupo y por lo tanto los valores de las variables estarán altamente correlacionados. 

<!-- La proporción de NA's en estas variables menor en este caso, alrededor del 20% con excepción del NH3 que presenta más de un 90% de datos faltantes. De nuevo el número de NA's puede deberse a los mismos motivos argumentados anteriormente y que comprobaremos más adelante en el análisis. Por otro lado, también tenemos unos pocos cientos de valores distintos para ser también variables numéricas continuas y esto puede deberse a las mismas causas argumentadas para los materiales particulados. -->

- *C7H8, C6H6, C8H10* son variables con datos sobre la concentración de estas moléculas orgánicas también consideradas contaminantes en el aire. 

<!-- De nuevo estas variables numéricas y continuas presentan datos faltantes por encima del 90% y muchos menos niveles distintos que observacioness de las variables. Podrían ofrecerse los mismos argumentos para explicar estos hechos. El porcentaje similar de datos faltantes podría se debido a que estas variables se miden al vez (en las mismas estaciones y períodos de tiempo). -->

- *Vel_viento, Dir_viento, Temperatura, Humidad_rel, Presion, Radiacion_solar, Precipitacion, Max_vel_viento* son variables numéricas con mediciones de estas distintas condiciones ambientales al momento de medir las concentraciones de moléculas contaminantes en el aire. 

<!-- Es interesante contar con estos datos para ver si influyen en los valores de contaminación. Estas variables presentan entre un 50-60% de datos faltantes que puede deberse a que no todas las estacione miden las condiciones ambientales. -->

- *As, Ni, Cd, Pb* son variables numéricas con datos de otras concentraciones de gases y metales contaminantes en el aire. 

<!-- Todos estas variables presentaban el prefijo (ng/m3) indicando las unidades en que se mide sus concentraciones. El resto de datos de concentraciones no presentan las unidades lo cuál nos hace sospechar que auiás los datos de estas variables fueron medidas en conjunto. Esto también explicaría que todos tengan el mismo porcentaje de datos faltantes (entorno al 98%). De nuevo, en el análisis comprobaremos a qué puede deberse esta cantidad de datos faltantes. -->

- *B(a)p* es una variable booleana que sólo presenta una observación. Elresto de datos son faltants y no podemos saber lo que representa esta variable.

- *Fecha_creación* y *Fecha_baja* son variables de tipo *Date* que parecen estar relacionadas con la creacion del dataset y que no parecen aportar información sobre nuestros datos. *Fecha_creación* solo presenta dos entradas distintas y *Fecha_baja* sólo presenta NA's por lo que estas variables parecen prescindibles.



```{r}
datos <-
  datos %>% select(
    -c(
      'Id',
      'Dia_de_la_semana',
      'Dia_del_mes',
      'Fecha_creacion',
      'Fecha_baja',
      'B(a)p'
    )
  )
```


# Análisis de datos faltantes y especiales

En esta sección, previamente al análisis univariante y bivariante de las variables, vamos a realizar un análisis de la estructura del dataset. El dataset parece estar compuesto por la unión de un conjunto datasets, posiblemente por las distintas estaciones de las que provienen los datos. Con el objetivo de obtener un conjunto de datos consistente, analizaremos el porcentaje de NA's que hay por cada variable, luego veremos que datos proporcionan las estaciones y con que frecuencia, también comprobaremos cuando comenzaron a generar datos las estaciones y durante que periodos de tiempo se han obtenido las variables. 

En primer lugar vamos reemplazar todos los posibles valores especiales (NULL, NaN, Inf...)  que pudieran haber en las variables numéricas de nuestro dataset por NA's. De esta forma podemos tratar todos estos datos que no tienen sentido a la vez.

```{r}
variables_numericas <- colnames(datos[sapply(datos, is.numeric)])
reemplazo_especiales <- function(x) {
  return(ifelse(is.finite(x), x, NA))
}
datos <-
  mutate(datos, across(all_of(variables_numericas), reemplazo_especiales))
```

En el Anexo 1, en la Figura \ref{tabla:anexo2} podemos confirmar los elevados porcentajes NA's. Como ya hemos comentado, pensamos que el elevado número de datos faltantes puede deberse a que algunas variables se miden en peródos de tiempo diferentes a las demás o a que no en todas las estaciones se miden todas las variables. Al unir los datos de las distintas estaciones por la fecha, se habrían dado lugar los NA's. Para comprobar esta teoría vamos a realizar una serie de representacions gráficas exploratorias.

En el mapa de calor de la Figura \ref{fig:mapa_calor}, podemos ver qué variables mide cada estación meteorológica, además de la cantidad de datos que aporta cada una de ellas sobre cada varaible numérica. Vemos como sólo hay dos estaciones (Viveros y Boulevard Sud) que miden las variables *As*, *Pb*, *Ni* y *Cd* y que su número de entradas es bajo en comparación con otras variable, quizá debido a que se empezaron a tomar datos de estas variables más tarde que el resto. En el caso del *NH3* vemos que solo se ha medido en la estación Boulevard Sud. Las moléculas orgánicas *C8H10*, *C6H6*, *C7H8* sólo se miden en las estaciones de Pista de Silla y Viveros. Cabe destacar también que las estaciones que miden mayor cantidad de variables son Pista de Silla, Viveros y Boulevard Sud. Por otro lado, estaciones como Conselleria Meteo y Nazaret Meteo sólo miden las condiciones ambientales y no las concentraciones de contaminantes, al igual que la estación del Puerto de Valencia con la diferencia que en esta además se miden los niveles de partículas *PM10* y de *SO2*. Además, vemos como en la estación de Valencia Olivereta sólo se miden niveles de partículas *PM2.5*, *PM10* y óxidos de nitrógeno.

Como podemos ver en la Figura \ref{fig:estaciones_activas}, desde 2004 hasta 2007 sólo tenemos datos de las estaciones de Pista de Silla y Viveros, que se mantienen actvas hasta 2022. Posteriormente, en los siguientes 5 años (2008-2012) se van añadiendo datos de otras estaciones como la del Politécnico, Av. de Francia, Molí del Sol, Boulevard Sur, Valencia Centro y Conselleria a razón casi de una nueva estación al año y que se mantienen hasta el final (2022). Desde 2013 hasta 2016 se siguen viendo las mismas estaciones y en los siguientes dos años (2017-2018) se añaden datos de la estación del Puerto de Valencia, de la que posteriormente dejamos de obtener datos. Finalmente, desde 2019 hasta 2022 se van añadiendo progresivamente cada año las estaciones de Nazaret, Puerto Molí Trans. Ponent, Puerto antic Turia y Valencia Olivereta. 2022 es el año donde tenemos datos de más estaciones distintas.

A partir del gráfico de la Figura \ref{fig:periodos_variables} podemos ver el periodo de tiempo en el que las variables comienzan a ser medidas. En concreto, los datos de *As*, *Cd*, *Ni*, *Pb* empiezan a tomarse sólo a partir de 2019. Además, terminan antes que el resto de variables, a principios del 2022.. Otras variables como *Precipitacion*, *Velocidad_maxima_del_viento*,*PM1* o *NH3* empiezan a tener datos un poco más tarde que el resto pero antes del 2019. Todas las demás variables presentan almenos algún dato en 2004.

<!-- Tras esta primera visualización de nuestros datos, podemos concluir que la gran cantidad de datos faltantes se debe a una combinación del hecho de que no todas las estaciones miden todas las variables, sumado a que los datos de ciertas variables se empiezan a medir posteriormente que el resto. Esto puede deberse a que la(s) estación(es) que recoge(n) datos de esta variable comienza(n) a funcionar en una fecha posterior al resto de estaciones o simplemente debido a que hasta cierto año no se instalan sensores en las estaciones para medir esas variables. En cualquier caso, dependiendo del análisis que se quiera realizar se habrán de escoger unas variables, y por ende un determinado número de estaciones que midan estas variables y un período de tiempo en que se estén recogiendo datos de estas variables. -->

En nuestro caso vamos a escoger un período de 10 años, desde 2012 a 2022, ya que en este período de tiempo hay un número significativo de estaciones recogiendo datos y la mayoría de las variables son medidas en este intervalo de tiempo de forma consistente. No obstante, decidimos descartar las variables *Pb*, *Cd*, *Ni*, *As*, *B(a)p* y *NH3* debido a que se comienzan a medir después del 2012 y resultaría poco razonable imputar los datos de estas variables en esos años. De la misma forma, también descartamos las variables *C7H8*, *C6H6*, y *C8H10* debido a que presentan grandes períodos de tiempo con ausencia de datos intercalados entre 2012 y 2022, por lo que también sería poco razonable imputar estos datos. 

```{r, include=FALSE}
porc_na <- function(x) {
  100 * sum(is.na(x)) / length(x)
}
res <- datos %>%
  summarise(across(.cols = all_of(colnames(datos)), .fns = porc_na)) %>%
  pivot_longer(cols = all_of(colnames(datos)),
               names_to = 'Variable',
               values_to = "Porcentaje NA's") %>%
  arrange(desc(`Porcentaje NA's`)) %>%
  mutate(`Porcentaje NA's` = round(`Porcentaje NA's`, digits = 2))

anexo2 <- kableExtra::kable(res, format = "latex", 
             booktabs = TRUE, 
             caption = "Porcentaje NA's de las variables\\label{tabla:anexo2}", 
             align = 'ccc', centering = FALSE,
             table.envir = "table", position = "H") %>%
  kableExtra::kable_styling(font_size=7)
```

```{r mapa_calor, fig.width=4.5, fig.height=3, fig.align='left', fig.cap="\\label{fig:mapa_calor}"}
num_entradas <- function(x) {
  sum(!is.na(x))
}
est_var <- datos %>%
  group_by(Estacion) %>%
  summarise(across(.cols = all_of(variables_numericas), .fns = num_entradas)) %>%
  pivot_longer(
    cols = all_of(variables_numericas),
    names_to = 'Variable',
    values_to = "Num_entradas"
  ) %>%
  mutate(Variable = factor(Variable, levels = variables_numericas, ordered = T)) %>%
  arrange(match(Variable, variables_numericas))

p <-
  ggplot(data = est_var, aes(x = Estacion, y = Variable, fill = Num_entradas)) +
  geom_tile() + scale_fill_gradient(low = "white", high = "blue") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 7), 
        axis.text.y = element_text(size = 6), 
        legend.title = element_text(size = 7),
        legend.text = element_text(size = 6))

show(p)
```

```{r estaciones_activas, fig.width=4.5, fig.height=3, fig.align='left', fig.cap="\\label{fig:estaciones_activas}"}
datos %>%
  mutate(ano = factor(year(Fecha))) %>%
  ggplot(aes(x = ano, fill = Estacion)) +
  geom_bar() +
  labs(x = 'Año') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 7),
        legend.text = element_text(size = 6),
        legend.title = element_text(size = 7),
        legend.key.width = unit(0.05, "cm"),
        legend.key.height = unit(0.05, "cm"))
```

```{r periodos_variables, fig.width=5.5, fig.height=4, fig.align='left', fig.cap="\\label{fig:periodos_variables}"}
datos %>%
  pivot_longer(
    cols = all_of(variables_numericas),
    names_to = 'Variables',
    values_to = 'valor',
    values_drop_na = T
  ) %>%
  mutate(Variables = factor(Variables, levels = variables_numericas, ordered = T)) %>%
  ggplot(aes(x = Fecha, y = valor, color = Variables)) +
  geom_line() +
  facet_wrap(Variables ~ ., scales = "free_y") +
  theme(legend.position = "none") +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 7),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
  ) +
  labs(y = NULL) +
  scale_colour_manual(values = rainbow(26)) 
```

# Análisis univariante

En esta sección analizaremos las variables de forma individual con el objetivo de conocer sus magnitudes, es decir, las unidades de medida que representan, y como se distribuyen. 
<!-- Como se ha mencionado previamente, escogemos los datos que comienzan en 2012, concretamente cunado se empiezan a tomar datos de la precipitación, y los datos previos a 2023, concretamente cuando se dejan de tomar los oxidos de nitrogeno. -->

<!-- Variables de interés -->
<!--   - Fecha -->
<!--   - Estación -->
<!--   - Gases: NO, NO2, NOx, SO2, CO, O3  -->
<!--   - Meteorológicas: Temperatura, Humedad, Presion, Velocidad viento, Direccion viento, Radiación solar, Precipitación -->
<!--   - Calidad de vida: Ruido -->

Comenzamos con un summary de las variables numéricas de interés para analizar las magnitudes de las variables y como se distribuyen los datos. El resultado de este sumario lo podemos ver en el Anexo 1 Tabla \ref{tabla:anexo3}. Mediante el sumario anterior podemos averiguar cuales son las unidades de medida empleadas contrastando con información externa, ya que en la fuente de los datos no se proporcionan.

  - Gases (NO, NO2, NOx, SO2, CO, O3): microgramos por metro cubico ($\mu$g/m3)
  - Temperatura: grados centígrados (Cº)
  - Humedad: porcentaje (%)
  - Presión: hectopascales (hPa)
  - Velocidad del viento: kilometros/hora (m/s)
  - Dirección del viento: ángulo de 0 a 360 (º)
  - Precipitación: litros de agua por metro cuadrado (mm)
  - Radiación solar: Vatios por metro cuadrado (W/m2)
  - Ruido: decibelios (dB)
  
También es interesante observar las distribuciones de estas variables. Esto podemos observarlo en las figuras \ref{densidades1} y \ref{densidades2}.

```{r, include=FALSE, fig.width=4, fig.height=4, fig.align='left'}
variables <-
  c(
    "Fecha",
    "Estacion",
    "NO",
    "NO2",
    "NOx",
    "SO2",
    "CO",
    "O3",
    "Temperatura",
    "Vel_viento",
    "Dir_viento",
    "Humedad_rel",
    "Presion",
    "Radiacion_solar",
    "Precipitacion",
    "Ruido"
  )

mystats <- function(x, na.omit = TRUE) {
  if (na.omit)
    x <- x[!is.na(x)]
  min <- min(x)
  Q1 <- quantile(x, 0.25)
  median <- median(x)
  mean <- mean(x)
  dt <- sd(x)
  Q3 <- quantile(x, 0.75)
  max <- max(x)
  
  n <- length(x)
  IQR <- IQR(x)
  
  return(round(
    c(
      min = min,
      Q1 = Q1,
      median = median,
      mean = mean,
      dt = dt,
      Q3 = Q3,
      max = max,
      n = n,
      IQR = IQR
    ),
    2
  ))
}

precipitacion <- datos[, c('Fecha', 'Precipitacion')] %>% na.omit
fecha_inicio <- precipitacion$Fecha[1]
oxidos_n <- datos[, c('Fecha', 'NOx')] %>% na.omit
fecha_fin <- oxidos_n$Fecha[nrow(oxidos_n)]

datos <-
  datos[datos$Fecha > fecha_inicio &
          datos$Fecha < fecha_fin, variables]

res <- sapply(datos[-c(1, 2)], mystats) %>% t

anexo3 <- kableExtra::kable(res, format = "latex", 
             booktabs = TRUE, 
             caption = "Sumario de variables numericas\\label{tabla:anexo3}", 
             align = 'ccc', centering = FALSE,
             table.envir = "table", position = "H") %>%
  kableExtra::kable_styling(font_size=7)
```

```{r densidades1, fig.width=5.5, fig.height=3.5, fig.align='left', fig.cap="\\label{fig:densidades1}"}
# Gases
datos[2:8] %>%
  pivot_longer(
    cols = 2:7,
    names_to = 'Variables',
    values_to = 'valor',
    values_drop_na = T
  ) %>%
  ggplot(aes(x = valor)) +
  geom_histogram(aes(
    y = stat(density),
    fill = 'blue',
    alpha = 0.6
  ), bins = 50) +
  geom_density() +
  facet_wrap( ~ Variables, scales = "free") +
  theme(legend.position = "none", 
    axis.text.x = element_text(size = 6),
    axis.text.y = element_text(size = 6)
  ) +
  labs(y = NULL)
```

```{r densidades2, fig.width=5.5, fig.height=4, fig.align='left', fig.cap="\\label{fig:densidades2}"}
# Meteorológicas y Ruido
datos[c(2, c(9:16))] %>%
  pivot_longer(
    cols = 2:9,
    names_to = 'Variables',
    values_to = 'valor',
    values_drop_na = T
  ) %>%
  ggplot(aes(x = valor)) +
  geom_histogram(aes(
    y = stat(density),
    fill = 'blue',
    alpha = 0.6
  ), bins = 50) +
  geom_density() +
  facet_wrap( ~ Variables, scales = "free") +
  theme(legend.position = "none", 
    axis.text.x = element_text(size = 6),
    axis.text.y = element_text(size = 6)
  ) +
  labs(y = NULL)
```


## Detección y eliminación de outliers con métodos univariante

A continuación, procederemos a detectar y eliminar outliers. Primero, comenzaremos definiendo diferentes funciones univariantes (tresSigma, hampel, boxplot y percentiles). Comprobaremos el funcionamiento de los métodos de detección de outliers sobre todas las variables numéricas y observaremos las diferencias. En la Figura \ref{fig:outliers_univ} podemos observar cómo la regla del percentil siempre elimina datos, esto es debido a la naturaleza de la regla, la cual siempre eliminará el 2.5% que quede por arriba y el 2.5% por abajo. Podemos usar esto como comparador de el resto de métodos.

El resto de métodos, en la mayoría de ocasiones quedan por debajo del criterio del percentil. No obstante, es visible el agresivo comportamiento de la regla boxplot y el excesivamente poco agresivo método de la regla 3-sigma. En cuanto al comportamiento de la regla de Hampel, parece comportarse como una versión agresiva pero manteniendo la prudencia de la regla 3-sigma.

<!-- Pese a que, según las matemáticas, cuantos más datos tenemos, más se parece la distribución de los mismos a una Gaussiana, hemos visto anteriormente que no todos los datos siguen esta distribución. -->

Hemos decidido utilizar la regla de Hampel para la detección de los outliers, ya que esta es una regla robusta a distribuciones que no sean Gaussianas. En cuanto a qué hacer con estos outliers, hemos decidido sustituirlos por NA para su posterior inputación.

```{r}
tresSigma <- function(x) {
  media <- mean(x, na.rm = TRUE)
  desviacion <- sd(x, na.rm = TRUE)
  lim_low <- media - 3 * desviacion
  lim_upp <- media + 3 * desviacion
  
  outliers <- x[x < lim_low | x > lim_upp]
  
  return(outliers)
}

hampel <- function(x) {
  mediana <- median(x, na.rm = TRUE)
  madm <- mad(x, constant = 1.4826, na.rm = TRUE)
  umbral <- 3 * madm
  
  outliers <- x[abs(x - mediana) > umbral]
  
  return(outliers)
}

boxplot <- function(x) {
  q1 <- quantile(x, 0.25, na.rm = TRUE)
  q3 <- quantile(x, 0.75, na.rm = TRUE)
  
  iqr <- q3 - q1
  
  lower_limit <- q1 - 1.5 * iqr
  upper_limit <- q3 + 1.5 * iqr
  
  outliers <- x[x < lower_limit | x > upper_limit]
  
  return(outliers)
}

percentil <- function(x) {
  p5 <- quantile(x, 0.05, na.rm = TRUE)
  p95 <- quantile(x, 0.95, na.rm = TRUE)
  
  outliers <- x[x < p5 | x > p95]
  
  return(outliers)
}

remove_outliers <- function(x, func) {
  outliers <- func(x)
  return(x[!is.na(outliers)])
}

replace_outliers <- function(x, func) {
  outliers <- func(x)
  x[outliers] <- NA
  return(x)
}
```

```{r ourliers_univ, fig.width=5.5, fig.height=3.7, fig.align='left', fig.cap="\\label{fig:outliers_univ}"}
columnas_numericas <- names(datos)[3:16]

m1 <- apply(datos[columnas_numericas], 2, tresSigma)
m2 <- apply(datos[columnas_numericas], 2, hampel)
m3 <- apply(datos[columnas_numericas], 2, boxplot)
m4 <- apply(datos[columnas_numericas], 2, percentil)
m1 <- sapply(sapply(m1, complete.cases), sum)
m2 <- sapply(sapply(m2, complete.cases), sum)
m3 <- sapply(sapply(m3, complete.cases), sum)
m4 <- sapply(sapply(m4, complete.cases), sum)

resultados <- data.frame(
  Metodo = rep(
    c("3-Sigma", "Hampel", "Boxplot", "Percentil"),
    each = length(columnas_numericas)
  ),
  Columna = rep(columnas_numericas, times = 4),
  Outliers_Detectados = c(m1, m2, m3, m4)
)
ggplot(resultados,
       aes(x = Columna, y = Outliers_Detectados, fill = Metodo)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(title = "Número de Outliers Detectados por Método",
       x = "Columna Numérica",
       y = "Número de Outliers Detectados") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
datos_no_outliers <- datos %>%
  mutate_at(vars(all_of(columnas_numericas)), ~ replace_outliers(., hampel))
```

# Analisis bivariante

Partiendo de las conclusiones obtenidas en el apartado de análisis de datos faltantes, nos parece interesante ver si existe alguna influencia en el valor de la variable por parte de la estación de la que proviene. En caso de no existir una influencia considerable podemos utilizar los valores obtenidos en otras estaciones para imputar otros. Finalmente comprobaremos si año influye en el valor de la variable, para ver si a lo largo del tiempo ha ocurrido algún cambio considerable.

Mediante boxplots vamos a analizar como se distribuyen los datos respecto a las estaciones. En la figura \ref{boxplot_est1} se observan las referentes a gases y en la figura \ref{boxplot_est2} el resto.

A partir de ambas figuras podemos concluir con que generalmente la estación no influye en los valores de las variables. Esta información nos es útil para la imputación de NA's, ya que podemos emplear la media de las medidas obtenidas por otras estaciones. Respecto al ruido, el cual únicamente se mide en las estaciones de "Pista Silla" y "Viveros" si parece tener un valor un poco mayor en "Pista Silla". Esto puede deberse a que esta estación se encuentra en un lugar con mayor tránsito de coches.

```{r boxplot_est1, fig.width=5.5, fig.height=3.3, fig.align='left', fig.cap="\\label{fig:boxplot_est1}"}
# Gases
datos_no_outliers %>%
  select(all_of(variables[2:8])) %>%
  pivot_longer(
    cols = 2:7,
    names_to = 'Variables',
    values_to = 'valor',
    values_drop_na = T
  ) %>%
  ggplot(aes(y = valor, fill = Estacion)) +
  geom_boxplot(outlier.size = 0.1, size = 0.2) +
  facet_wrap( ~ Variables, scales = "free_y") +
  theme(axis.text.x = element_blank(), legend.position = "none")
```

```{r boxplot_est2, fig.width=5.5, fig.height=3.5, fig.align='left', fig.cap="\\label{fig:boxplot_est2}"}
# Variables meteorológicas y ruido
datos_no_outliers %>%
  select(all_of(variables[c(2, c(9:16))])) %>%
  pivot_longer(
    cols = 2:9,
    names_to = 'Variables',
    values_to = 'valor',
    values_drop_na = T
  ) %>%
  ggplot(aes(y = valor, fill = Estacion)) +
  geom_boxplot(outlier.size = 0.1, size = 0.2) +
  facet_wrap( ~ Variables, scales = "free_y") +
  theme(axis.text.x = element_blank(), legend.position = "none")
```

También visualizaremos la evolución mediante boxplots de el valor de las variables a lo largo de los años. En la Figura \ref{fig:boxplot_anos1} se puede apreciar una leve reducción a lo largo de los años de los gases considerados como contaminantes a excepción del SO2 que parece mantenerse constante. Por otro lado vemos un leve aumento del ozono (O3), por lo que podría existir una relación con la disminución de gases contaminantes. Continuamos con las variables meteorológicas. Como era de esperar, en la Figura \ref{fig:boxplot_anos2} vemos como las variables meteorológicas no han sufrido variaciones a lo largo de los años. Por otro lado si que se aprecia un leve aumento en el ruido.

```{r boxplot_anos1, fig.width=5.5, fig.height=3.3, fig.align='left', fig.cap="\\label{fig:boxplot_anos1}"}
# Gases
datos_no_outliers %>%
  select(all_of(variables[c(1, 3:8)])) %>%
  mutate(ano = factor(year(Fecha))) %>%
  pivot_longer(
    cols = 2:7,
    names_to = 'Variables',
    values_to = 'valor',
    values_drop_na = T
  ) %>%
  ggplot(aes(y = valor, fill = ano)) +
  geom_boxplot(outlier.size = 0.1, size = 0.2) +
  facet_wrap( ~ Variables, scales = "free_y") +
  theme(axis.text.x = element_blank(), legend.position = "none")
```

```{r boxplot_anos2, fig.width=5.5, fig.height=3.5, fig.align='left', fig.cap="\\label{fig:boxplot_anos2}"}
# Gases
datos_no_outliers %>%
  select(all_of(variables[c(1, 9:16)])) %>%
  mutate(ano = factor(year(Fecha))) %>%
  pivot_longer(
    cols = 2:9,
    names_to = 'Variables',
    values_to = 'valor',
    values_drop_na = T
  ) %>%
  ggplot(aes(y = valor, fill = ano)) +
  geom_boxplot(outlier.size = 0.1, size = 0.2) +
  facet_wrap( ~ Variables, scales = "free_y") +
  theme(axis.text.x = element_blank(), legend.position = "none")
```

## Imputación de datos anómalos

Ahora que conocemos las unidades de nuestras variables tras haberlas analizado, sabemos cuál es el rango de valores puede tomar cada una. 
<!-- Así, sabemos que a excepción de la temperatura (medida en ºC) no tiene sentido que ninguna del resto de variables relacionadas con las condiciones ambientales (Humedad, dirección del viento, presión ...) tengan valores menores que 0, al igual que las concentraciones de los gases. Explorando el dataset con la función _View()_, vemos por ejemplo que la Radiación solar presenta un valor negativo.  -->
Para tratar estos datos anómalos, en primer lugar se convertirán en NA's y a continuación se les imputará un valor igual que el resto de datos faltantes.

```{r}
variables_numericas <- 
  variables_numericas <- 
  colnames(datos_no_outliers[sapply(datos_no_outliers, is.numeric)])

reemplazo_anomalos <- function(x){
  ifelse(x < 0, NA, x)
}
datos_no_outliers <- datos_no_outliers %>% 
  mutate(across(.cols = all_of(variables_numericas[variables_numericas != "Temperatura"]), 
                .fns = reemplazo_anomalos))
```

<!-- Si bien nuestras variables de interés son más consistentes en comparación a las descartadas en lo que se refiere a las entradas diarias de cada variable, estas todavía presentan muchos datos faltantes. No obstante,  -->

En el anáslisis univariante vimos que los datos diarios de las variables en todas las estaciones de Valencia suelen ser parecido. Decidimos usar este hecho para imputar los datos faltantes en cada día con la media de esta variable sobre todas las estaciones. 

<!-- Tras realizar esta imputación, todavía hay algunas variables que presentan NA's, esto se debe a que hay algunos días donde donde esta variable no se ha medido en ninguna de las estaciones. Esto sólo ocurre en el ~11% de las observaciones, por lo que decidimos desprendernos de estas observaciones, ya que el volúmen de datos es suficientemente grande y los datos todavía podrían considerarse diarios. -->

```{r}
imputacion_NAs <- function(x) {
  ifelse(is.na(x), mean(x, na.rm = T), x)
}

datos_limpios <- datos_no_outliers %>%
  group_by(Fecha) %>%
  mutate(across(.cols = all_of(columnas_numericas), imputacion_NAs)) %>%
  mutate(across(all_of(columnas_numericas), reemplazo_especiales)) %>%
  ungroup

#100 * sum(complete.cases(datos_limpios)) / nrow(datos_limpios)

datos_limpios <- datos_limpios[complete.cases(datos_limpios), ]
```
## Correlaciones

<!-- La correlación puede tener valores en el rango [-1,1]. Siendo -1 el indicador de un comportamiento absolutamente contrario y siendo 1 la misma variable, pues tiene exactamente el mismo comportamiento. Esto puede darnos información para reflexionar sobre la naturaleza y comportamiento de los datos. -->

Basándonos en la Figura \ref{fig:correlaciones1}, podemos extraer las siguientes conclusiones:

+ Existe una correlación negativa importante entre NOs y Ozono. Esto podría deberse a que la presencia de óxidos de nitrógeno puede contribuir a la degradación del ozono en la atmósfera, lo que tiene implicaciones para la calidad del aire, la contaminación y el efecto hivernadero.

+ Correlación positiva de NOx con el resto de NO (NO, NO2...). Como era de esperar y como se ha mencionado en la definición de las variables, NOx representa el conjunto de oxidos de nitrogeno, entre ellos el NO y el NO2.

+ Correlación positiva entre Temperatura y Radiación Solar. Esto es coherente con las estaciones más cálidas que a menudo experimentan más horas de sol y mayor radiación solar.

+ Correlación entre Radiación Solar y Ozono. Esto tiene sentido ya que la capa de ozono filtra la mayor parte de la radiación ultravioleta proveniente del sol, por lo tanto están muy relacionados entre ellos.

```{r, include=FALSE}
library(GGally)

# Correlacion Pearson
corr_P <- datos_limpios[3:15] %>%
  na.omit %>%
  cor
corr_P

# Correlacion Spearman
corr_S <- datos_limpios[3:15] %>%
  na.omit %>%
  cor(method = 'spearman')
corr_S
```


```{r correlaciones1, fig.width=5.5, fig.height=4, fig.align='left', fig.cap="\\label{fig:correlaciones1}"}
ggcorr(datos_limpios[3:15])
```

<!-- También hemos filtrado las correlaciones para mostrar únicamente las mayores correlaciones. Hemos puesto un umbral para escoger solo las correlaciones que sean mayores a 0.7 para visualizar las variables muy correlacionadas (eliminando las correlaciones de una variable con ella misma). Hemos puesto el ejemplo en el que las correlaciones son directas para la siguiente visualización. Podría realizarse esto para las correlaciones inversas. -->

```{r correlaciones2, eval=FALSE, fig.width=5.5, fig.height=4, fig.align='left', fig.cap="\\label{fig:correlaciones2}"}
df <- cor(na.omit(datos_limpios[3:15])) %>%
  as.data.frame(.)

df$Variable1 <- rownames(df)

cor <- df %>%
  pivot_longer(cols = -Variable1,
               names_to = "Variable2",
               values_to = "Correlation")

correlaciones <-
  cor[cor$Correlation > 0.7, ] %>% arrange(desc(Correlation)) %>% filter(Variable1 != Variable2)
correlaciones_inversas <-
  cor[cor$Correlation < -0.7, ] %>% arrange(Correlation) %>% filter(Variable1 != Variable2)
paste0(
  "El numero total de correlaciones inversas es ",
  nrow(correlaciones_inversas),
  ". Por lo tanto, solo estudiaremos las correlaciones directas"
)

ggplot(correlaciones,
       aes(x = Variable1, y = Variable2, color = Correlation)) +
  geom_tile(aes(fill = Correlation)) +
  theme_minimal() +
  labs(title = "Correlaciones Positivas")
```

## Detección y eliminación de outliers con métodos multivariable

La distancia de Mahalanobis mide la distancia de un punto de datos a un conjunto de datos multivariado centrado y escalado según la matriz de covarianza. Los puntos que tienen distancias de Mahalanobis más grandes son considerados como outliers, ya que están más lejos de la distribución típica de los datos. En otras palabras: con estos métodos multivariable no nos fijamos en que un valor sea anómalo, sino una combinación de estos, siendo representados en un espacio vectorial y midiendo la distancia de cada punto (muestra) con el resto.

Lo que haremos al encontrar un outlier será eliminarlo directamente, pues toda la muestra será anómala.

```{r, include=FALSE}
distancia_mahalanobis <- function(x) {
  media = colMeans(x)
  S = cov(x)
  
  dist = mahalanobis(x, media, S)
  umbral <- qchisq(0.95, df = ncol(x))
  
  outliers <- which(dist > umbral)
  
  return(outliers)
}

instancias_outliers <-
  distancia_mahalanobis(datos_limpios[columnas_numericas])
paste0(
  "La distancia de mahalanobis detecta como outliers ",
  length(instancias_outliers),
  " datos con una confianza del 95%. Con estos datos, lo que haremos no es cambiarlos por NA (pues miramos sobre instancias enteras), sino que directamente las eliminaremos."
)

datos_limpios_sin_outliers <- datos_limpios[-instancias_outliers, ]
```

# Resolución de preguntas planteadas sobre los datos

## Influencia de carril bici

Para estudiar la influencia de un carril bici por el centro de Valencia, estudiaremos la evolución de gases contaminantes en diversas estaciones de la ciudad. Mediremos la evolución de los gases:

+ SO2: Originado sobre todo durante la combustión de carburantes fósiles.
+ NO2: Es un contaminante atmosférico cuyas fuentes fundamentales son el tráfico rodado, así como las emisiones de determinadas industrias y grandes instalaciones de combustión.

Además, las estaciones deberían ser las más céntricas, ya que ahí el efecto del carril bici y las restricciones de acceso deberían hacerse más notables. Observaremos las siguientes estaciones:

+ Avda. Francia
+ Bulevard Sud
+ Valencia Centro
+ Olivereta

Si bien, en la Figura \ref{fig:pregunta1_1} no se observan cambios significativos en los niveles de SO2, en la Figura \ref{fig:pregunta1_2} sí que podemos observar una evolución en los niveles de NO2.

Respecto al NO2 si que se puede apreciar una reducción a lo largo de los años. Con unos niveles más bajos especialmente en los últimos 3 años. Además se puede apreciar una periodicidad, concretamente una reducción de los niveles de NO2 en los meses de verano. Esto coincide con el momento del año donde menos gente vive en la ciudad y por lo tanto menos tráfico hay. En conclusión parece que las medidas de transporte que se han tomado en la ciudad han influenciado en la reducción de gases contaminantes.


```{r pregunta1_1, fig.width=4, fig.height=3, fig.align='left', fig.cap="\\label{fig:pregunta1_1}"}
datos_mensuales <- datos[c("Fecha", "SO2", "NO2", "Estacion")] %>%
  filter(Estacion %in% c("Avda. Francia", "Bulevard Sud", "Valencia Centro", "Olivereta")) %>%
  mutate(ano = year(Fecha), mes = month(Fecha)) %>%
  arrange(Fecha) %>%
  group_by(ano, mes) %>%
  summarise(
    media_SO2 = mean(SO2, na.rm = TRUE),
    media_NO2 = mean(NO2, na.rm = TRUE),
    .groups = "drop"
  )

ggplot(data = datos_mensuales, aes(
  x = mes,
  y = media_SO2,
  group = ano,
  color = factor(ano)
)) +
  geom_line() +
  labs(x = "Mes", y = "Media SO2", title = "Media Mensual SO2 por Año") +
  scale_color_discrete(name = "Año") +
  scale_x_continuous(breaks = 1:12,
                     labels = month.abb,
                     limits = c(1, 12)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


```{r pregunta1_2, fig.width=4, fig.height=3, fig.align='left', fig.cap="\\label{fig:pregunta1_2}"}
ggplot(data = datos_mensuales, aes(
  x = mes,
  y = media_NO2,
  group = ano,
  color = factor(ano)
)) +
  geom_line() +
  labs(x = "Mes", y = "Media NO2", title = "Media Mensual NO2 por Año") +
  scale_color_discrete(name = "Año") +
  scale_x_continuous(breaks = 1:12,
                     labels = month.abb,
                     limits = c(1, 12)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Relación entre la calidad del aire y el dia de la semana

En esta pregunta observamos si, en general la calidad del aire se ve influenciada por el día de la semana. Queremos sobre todo fijarnos en la distinción entre días laborables y de descanso. Podemos comprobar cómo, efectivamente, existe una disminución en los gases contaminantes los días festivos con respecto a los días laborables.

```{r pregunta2, fig.width=4, fig.height=3, fig.align='left', fig.cap="\\label{fig:pregunta2}"}
gases_interes <- c("NO", "NO2", "NOx", "SO2", "CO")

datos_semanales <- datos_limpios %>%
  mutate(Dia_de_la_semana = factor(wday(Fecha))) %>%
  filter(!(Dia_de_la_semana %in% c(1, 6))) %>%
  select(gases_interes) %>%
  summarise_all(.funs = list(mean)) %>%
  pivot_longer(cols = everything(),
               names_to = "Gas",
               values_to = "Valor")

datos_festivos <- datos_limpios %>%
  mutate(Dia_de_la_semana = factor(wday(Fecha))) %>%
  filter(Dia_de_la_semana %in% c(1, 6)) %>%
  select(gases_interes) %>%
  summarise_all(.funs = list(mean)) %>%
  pivot_longer(cols = everything(),
               names_to = "Gas",
               values_to = "Valor")

datos_combinados <- rbind(
  transform(datos_semanales, Tipo = "Semanal"),
  transform(datos_festivos, Tipo = "Festivo")
)

ggplot(datos_combinados, aes(x = Gas, y = Valor, fill = Tipo)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(title = "Valores de Gases Semanales y Festivos",
       x = "Gas",
       y = "Valor") +
  scale_fill_manual(values = c("Semanal" = "blue", "Festivo" = "red")) +
  theme_minimal() +
  theme(legend.title = element_blank())
```

## Evolución de la contaminación sonora a lo largo de los años

En la Figura \ref{fig:pregunta3_1} podemos observar un incremento visibleen la medición del ruido medio a lo largo de los años. Obviamente, en los datos del 2020 podemos observar un decrecimiento de los mismos, producto del parón de la pandemia, pero vemos cómo continúa aun así subiendo.

Con la figura \ref{fig:pregunta3_2} comprobaremos si este ruido medido depende de la zona dónde la midamos. Para ello, vamos a observar el comportamiento de la varianza de la media de los ruidos agrupados por estaciones. Calcularemos la desviación para cada año y, finalmente, la media de todas las desviaciones Si el valor es pequeño, entonces podemos afirmar que el incremento en el ruido no es de ciertas zonas, sino generalizado. Podemos observar que, para los valores que tratamos (sobre 50 y 60), una desviación del 0.3 es despreciable. Lo que sí que podemos determinar, gracias a contrastar estos datos con los de la gráfica boxplot \ref{boxplot_anos2}, es que la evolución en el ruido no viene dada por una tendencia natural. Más bien, el gráfico nos indica que existe un aumento significativo de ruido pero en días concretos.

```{r pregunta3_1, fig.width=4, fig.height=3, fig.align='left', fig.cap="\\label{fig:pregunta3_1}"}
datos_ruido <- datos_limpios[c("Fecha", "Ruido")] %>%
  mutate(Ano = year(Fecha)) %>%
  select(-Fecha) %>%
  group_by(Ano) %>%
  summarize(Media_Ruido = mean(Ruido, na.rm = TRUE, .groups = "drop"))

ggplot(datos_ruido, aes(x = Ano, y = Media_Ruido)) +
  geom_line() +
  labs(x = "Año", y = "Media de Ruido") +
  theme_minimal() +
  scale_y_continuous(limits = c(min(datos_ruido$Media_Ruido), max(datos_ruido$Media_Ruido)))
```

```{r pregunta3_2, fig.width=4, fig.height=3, fig.align='left', fig.cap="\\label{fig:pregunta3_2}"}
datos_ruido_estaciones <-
  datos_limpios[c("Fecha", "Estacion", "Ruido")] %>%
  mutate(Ano = year(Fecha)) %>%
  select(-Fecha) %>%
  group_by(Ano, Estacion) %>%
  summarize(Media_Ruido = mean(Ruido, na.rm = TRUE, .groups = "drop")) %>%
  group_by(Ano) %>%
  summarize(Desviacion_por_ano = sd(Media_Ruido, na.rm = TRUE))

ggplot(datos_ruido_estaciones, aes(x = Ano, y = Desviacion_por_ano)) +
  geom_line() +
  labs(x = "Año", y = "Desviacion de ruido por estación") +
  theme_minimal()
```


```{r include=FALSE}
mean(datos_ruido_estaciones$Desviacion_por_ano)
```

## Evolución de la temperatura a lo largo de los años

En la Figura \ref{fig:pregunta4} se puede observar el aumento generalizado de la temperatura a lo largo de los años. Es curioso que, pese a que en el mundo existe un aumento generalizado de la temperatura, en Valencia estuvo bajando esta tendencia y no es hasta el año 2017 que comenzaron a subir de nuevo. Pese a lo mencionado, bastante visible el hecho de que nos encontramos en una tendencia creciente.

```{r pregunta4, fig.width=4, fig.height=3, fig.align='left', fig.cap="\\label{fig:pregunta4}"}
datos_temperatura <- datos_limpios[c("Fecha", "Temperatura")] %>%
  mutate(Ano = year(Fecha)) %>%
  select(-Fecha) %>%
  group_by(Ano) %>%
  summarize(Media_Temperatura = mean(Temperatura, na.rm = TRUE, .groups = "drop"))

ggplot(datos_temperatura, aes(x = Ano, y = Media_Temperatura)) +
  geom_line() +
  labs(x = "Año", y = "Media de Temperatura") +
  theme_minimal() +
  scale_y_continuous(limits = c(
    min(datos_temperatura$Media_Temperatura),
    max(datos_temperatura$Media_Temperatura)
  ))
```

## Cómo se ha comportado la contaminación a lo largo de los años

Cuando contestamos a la primera pregunta, nos centramos en gases que soltaban los carburantes y solo observamos las estaciones más cercanas al centro de Valencia. En esta ocasión, estudiaremos el comportamiento de todos los gases contaminantes en todas las estaciones. Gracias a superponer todas estas evoluciones en un mismo gráfico, podemos tomar perspectiva y comparar el comportamiento entre los diferentes gases.

Esta vez, en la Figrua \ref{fig:pregunta5} podemos observar que se produjo un pico de todos los gases en el año 2016, pero que por lo general las medidas de estos se han mantenido bastante estables o incluso decrecientes en el tiempo.

Con las gráficas de la figura \ref{boxplot_anos1} podemos contrastar la información que nos otorga esta gráfica. Por ejemplo: 

+ El CO sí parece decrecer en el últimio año. Sin embargo, por los outliers y el rango de valores que se maneja, en el gráfico presente puede no apreciarse esta evolución.
+ Por ejemplo, en evoluciones como la del NO2 podemos reforzar la fiabilidad observando cómo la tendencia en su representación de boxplot es similar. Incluso parece haber consistencia en los datos que la regla boxplot marca como outliers.
+ En el gas SO2, observamos una tendencia estable a lo largo de los años. No obstante, comparando con su contraparte representada en boxplot ganamos la información de que el gas ha ido ganando estabilidad, habiendo cada vez menos outliers y más cercanos a los valores comunes conforme ha avanzado el tiempo.


```{r pregunta5, fig.width=4, fig.height=3, fig.align='left', fig.cap="\\label{fig:pregunta5}", fig.pos='H', warning=FALSE}
datos_gases <-
  datos_limpios[c("Fecha", "NO", "NO2", "NOx", "SO2", "CO")] %>%
  mutate(Ano = year(Fecha)) %>%
  select(-Fecha) %>%
  pivot_longer(
    cols = c("NO", "NO2", "NOx", "SO2", "CO"),
    names_to = "Gas",
    values_to = "Valor"
  ) %>%
  group_by(Ano, Gas) %>%
  summarize(Media = mean(Valor, na.rm = TRUE, .groups = "drop"))

ggplot(datos_gases, aes(x = Ano, y = Media, color = Gas)) +
  geom_line() +
  labs(x = "Año") +
  theme_minimal()
```

# Anexo 1 {#Anexo}

```{r anexo1, fig.pos='H'}
anexo1
```

```{r anexo2, fig.pos='H'}
anexo2
```

```{r anexo3, fig.pos='H'}
anexo3
```

